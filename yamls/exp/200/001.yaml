defaults:
  - 200/base@_here_


model_name: microsoft/deberta-v3-large
sep_token : [SEP]

early_stopping_patience: 3

training_args:
  gradient_accumulation_steps: 2
  gradient_checkpointing: true
  per_device_train_batch_size: 2
  per_device_eval_batch_size: 2
  optim: adamw_bnb_8bit

max_length: 200 # 200: 211h # 400: 450h

additional_data_paths: 
  - preprocessed/231_retrieve/000/6000_train_examples.csv
  - preprocessed/231_retrieve/000/extra_train_set.csv
  - preprocessed/231_retrieve/000/15k_gpt3.5-turbo.csv
  - preprocessed/231_retrieve/000/5900_examples.csv
  - preprocessed/231_retrieve/000/test.csv # 3k
  - preprocessed/231_retrieve/000/stem_1k_v1.csv

valid_data_paths: 
  preprocessed/231_retrieve/000/train.csv: 200
  preprocessed/231_retrieve/000/6000_wiki_en_sci_questions.csv: 2000