defaults:
  - 007/base@_here_


model_name: microsoft/deberta-v3-large
sep_token : [SEP]

training_args:
  gradient_accumulation_steps: 4
  gradient_checkpointing: true
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  optim: adamw_bnb_8bit

max_length: 200 # 200: 211h # 400: 450h

additional_data_paths: 
  - preprocessed/002_gpu/003/6000_train_examples.csv
  - preprocessed/002_gpu/003/extra_train_set.csv
  - preprocessed/002_gpu/003/15k_gpt3.5-turbo.csv
  - preprocessed/002_gpu/003/5900_examples.csv
  - preprocessed/002_gpu/003/test.csv # 3k
  - preprocessed/002_gpu/003/stem_1k_v1.csv

valid_data_paths: 
  preprocessed/002_gpu/003/train.csv: 200
  preprocessed/002_gpu/003/6000_wiki_en_sci_questions.csv: 2000