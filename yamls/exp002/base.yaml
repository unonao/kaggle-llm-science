debug: ${debug}
seed: 7
model_name: microsoft/deberta-v3-base
early_stopping_patience: 5

training_args:
  fp16: true
  warmup_ratio: 0.8
  learning_rate: 5.0e-06
  weight_decay: 0.01
  dataloader_num_workers: 8
  per_device_train_batch_size: 10
  per_device_eval_batch_size: 10
  num_train_epochs: 30
  logging_strategy: epoch
  evaluation_strategy: epoch
  save_strategy: epoch
  metric_for_best_model: map@3
  save_total_limit: 1
  load_best_model_at_end: true
  report_to: wandb
  output_dir: ""
  seed: ${..seed}
  
comp_data_path: input/kaggle-llm-science-exam
