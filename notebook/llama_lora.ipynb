{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63631186-0aef-4033-ad65-656ca0f7f797",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/working\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/working'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd ..\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fc652df-4146-4d58-9aaa-67c6bcd89a31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Optional, Union\n",
    "\n",
    "import hydra\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from hydra.core.hydra_config import HydraConfig\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoModelForMultipleChoice,\n",
    "    AutoTokenizer,\n",
    "    EarlyStoppingCallback,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from transformers.tokenization_utils_base import PaddingStrategy, PreTrainedTokenizerBase\n",
    "\n",
    "import wandb\n",
    "\n",
    "sys.path.append(os.pardir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a8a51a9-b19e-40a0-bcb7-1cb4524b7dd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug: false\n",
      "seed: 7\n",
      "early_stopping_patience: 3\n",
      "training_args:\n",
      "  fp16: true\n",
      "  warmup_ratio: 0.8\n",
      "  learning_rate: 5.0e-06\n",
      "  weight_decay: 0.01\n",
      "  dataloader_num_workers: 8\n",
      "  per_device_train_batch_size: 2\n",
      "  per_device_eval_batch_size: 2\n",
      "  num_train_epochs: 30\n",
      "  logging_strategy: steps\n",
      "  evaluation_strategy: steps\n",
      "  save_strategy: steps\n",
      "  logging_steps: 5000\n",
      "  save_steps: 5000\n",
      "  metric_for_best_model: map@3\n",
      "  save_total_limit: 1\n",
      "  load_best_model_at_end: true\n",
      "  report_to: wandb\n",
      "  output_dir: output/ipykernel_launcher/000\n",
      "  seed: 7\n",
      "  gradient_accumulation_steps: 2\n",
      "  gradient_checkpointing: true\n",
      "  optim: adamw_bnb_8bit\n",
      "model_name: tiiuae/falcon-7b\n",
      "sep_token:\n",
      "- SEP\n",
      "max_length: 150\n",
      "max_length_valid: 300\n",
      "data0_paths:\n",
      "- preprocessed/331_retrieve_b/000/data0_0.csv\n",
      "- preprocessed/331_retrieve_b/000/data0_10000.csv\n",
      "- preprocessed/331_retrieve_b/000/data0_20000.csv\n",
      "- preprocessed/331_retrieve_b/000/data0_30000.csv\n",
      "- preprocessed/331_retrieve_b/000/data0_40000.csv\n",
      "- preprocessed/331_retrieve_b/000/data0_50000.csv\n",
      "data1_path: preprocessed/331_retrieve_b/000/data1.csv\n",
      "data2_path: preprocessed/331_retrieve_b/000/data2.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "with initialize(version_base=None, config_path=\"../yamls\"):\n",
    "    c = compose(config_name=\"config\", overrides=[\"exp=305/000\"], return_hydra_config=True)\n",
    "    OmegaConf.resolve(c)  # debugやseedを解決\n",
    "    cfg = c.exp\n",
    "    runtime_choices = c.hydra.runtime.choices\n",
    "    exp_name = f\"{Path(sys.argv[0]).stem}/{runtime_choices.check}\"\n",
    "    output_path = Path(f\"./output/{exp_name}\")  #\n",
    "    cfg.training_args.output_dir = str(output_path)\n",
    "    print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "950867cf-5ef3-45de-9632-224e0799db8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/working'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b28532d1-7e78-4fe3-a13c-6ca75a11000f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./preprocessed/336_retrieve_b_improve/b_bge_10_4_3/data1.csv\").head().reset_index(drop=True)\n",
    "df_valid = pd.read_csv(\"./preprocessed/336_retrieve_b_improve/b_bge_10_4_3/train.csv\").head().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e50085e-5f93-43bb-821a-4162269e85eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "\n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.replace('\"', \"\")\n",
    "    text = text.replace(\"“\", \"\")\n",
    "    text = text.replace(\"”\", \"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4fe0f07-8bc1-4ae4-95ae-3911a774b683",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_df(df, mode=\"train\"):\n",
    "    max_length = cfg.max_length if mode == \"train\" else cfg.max_length_valid  # 推論時はtokenを長く取る\n",
    "    df[\"context\"] = df[\"context\"].apply(lambda x: \" \".join(x.split()[:max_length]))\n",
    "\n",
    "    # 空を埋める\n",
    "    options = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "    for option in options:\n",
    "        df[option] = df[option].fillna(\"\")\n",
    "    return df\n",
    "\n",
    "\n",
    "df_train = preprocess_df(df_train)\n",
    "df_valid = preprocess_df(df_valid, mode=\"valid\")\n",
    "dataset_train = Dataset.from_pandas(df_train)\n",
    "dataset_valid = Dataset.from_pandas(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dfff259-349e-4b62-8f03-7419e69428c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Context\n",
       "\n",
       "Henry Clay (disambiguation) > Henry Clay (1777–1852) was an American politician from Kentucky. If an internal link led you here, you may wish to change the link to point directly to the intended article. Henry Clay > Many monuments, memorials, and even high schools have been erected and named in honor of Clay. Sixteen counties, one each in Alabama, Florida, Georgia, Illinois, Indiana, Kansas, Kentucky, Minnesota, Mississippi, Missouri, Nebraska, North Carolina, South Dakota, Tennessee, Texas, and West Virginia, are named for Clay. Communities named for Clay include Clay, Kentucky, Claysville, Alabama and Claysville, Pennsylvania. The United States Navy named a submarine, the USS Henry Clay, in his honor. List of things named for Henry Clay > Sixteen Clay counties in the United States, in Alabama, Florida, Georgia, Illinois, Indiana, Kansas, Kentucky, Minnesota, Mississippi, Missouri, Nebraska, North Carolina, South Dakota, Tennessee, Texas, and West Virginia. (Clay County, Iowa is named for\n",
       "\n",
       "## Prompt\n",
       "\n",
       "Answer the following multiple choice question by giving the most appropriate response. Answer should be one among [A, B, C, D, E]\n",
       "\n",
       "## Question\n",
       "\n",
       "Whose name was Clay County in Kansas named after?\n",
       "\n",
       "A) Henry Clay, a famous scientist\n",
       "\n",
       "B) Henry Clay, a renowned painter\n",
       "\n",
       "C) Henry Clay, a famous explorer\n",
       "\n",
       "D) Henry Clay, an influential U.S. Senator from Kentucky\n",
       "\n",
       "E) Henry Clay, a former president of the United States\n",
       "\n",
       "\n",
       "## Answer: D) Henry Clay, an influential U.S. Senator from Kentucky\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b24e08470a944bd399c43ca1a1e13448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be40b608864f4fe68b36d79360281ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"## Context\\n\n",
    "{context}\n",
    "\n",
    "## Prompt\\n\n",
    "Answer the following multiple choice question by giving the most appropriate response. Answer should be one among [A, B, C, D, E]\n",
    "\n",
    "## Question\\n\n",
    "{prompt}\\n\n",
    "A) {a}\\n\n",
    "B) {b}\\n\n",
    "C) {c}\\n\n",
    "D) {d}\\n\n",
    "E) {e}\\n\n",
    "\n",
    "## Answer: {answer}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"prompt\", \"a\", \"b\", \"c\", \"d\", \"e\", \"answer\"])\n",
    "\n",
    "# sample\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "sample = dataset_train[0]\n",
    "display(\n",
    "    Markdown(\n",
    "        prompt.format(\n",
    "            context=sample[\"context\"],\n",
    "            prompt=sample[\"prompt\"],\n",
    "            a=sample[\"A\"],\n",
    "            b=sample[\"B\"],\n",
    "            c=sample[\"C\"],\n",
    "            d=sample[\"D\"],\n",
    "            e=sample[\"E\"],\n",
    "            answer=f'{sample[\"answer\"]}) {sample[sample[\"answer\"]]}',\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "def format_text(example):\n",
    "    text = prompt.format(\n",
    "        context=sample[\"context\"],\n",
    "        prompt=sample[\"prompt\"],\n",
    "        a=sample[\"A\"],\n",
    "        b=sample[\"B\"],\n",
    "        c=sample[\"C\"],\n",
    "        d=sample[\"D\"],\n",
    "        e=sample[\"E\"],\n",
    "        answer=f'{sample[\"answer\"]}) {sample[sample[\"answer\"]]}',\n",
    "    )\n",
    "    return {\"text\": text}\n",
    "\n",
    "\n",
    "tokenized_dataset_train = dataset_train.map(format_text)\n",
    "tokenized_dataset_valid = dataset_valid.map(format_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff587016-6190-4ac7-9bc0-1f7afbf81ab0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/philippsinger/h2ogpt-perplexity-ranking\n",
    "def precision_at_k(r, k):\n",
    "    \"\"\"Precision at k\"\"\"\n",
    "    assert k <= len(r)\n",
    "    assert k != 0\n",
    "    return sum(int(x) for x in r[:k]) / k\n",
    "\n",
    "\n",
    "def map_k(true_items, predictions, K=3):\n",
    "    \"\"\"Score is mean average precision at 3\"\"\"\n",
    "    U = len(predictions)\n",
    "    map_at_k = 0.0\n",
    "    for u in range(U):\n",
    "        user_preds = predictions[u]\n",
    "        user_true = true_items[u]\n",
    "        user_results = [1 if item == user_true else 0 for item in user_preds]\n",
    "        for k in range(min(len(user_preds), K)):\n",
    "            map_at_k += precision_at_k(user_results, k + 1) * user_results[k]\n",
    "    return map_at_k / U\n",
    "\n",
    "\n",
    "def predictions_to_map_output(predictions):\n",
    "    sorted_answer_indices = np.argsort(-predictions)  # Sortting indices in descending order\n",
    "    top_answer_indices = sorted_answer_indices[:, :]  # Taking the first three indices for each row\n",
    "    top_answers = np.vectorize(index_to_option.get)(\n",
    "        top_answer_indices\n",
    "    )  # Transforming indices to options - i.e., 0 --> A\n",
    "    return np.apply_along_axis(lambda row: \" \".join(row), 1, top_answers)\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    y_pred = predictions_to_map_output(logits)\n",
    "    y_true = [index_to_option[label] for label in labels]\n",
    "    return {cfg.training_args.metric_for_best_model: map_k(y_true, y_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f168d507-a273-4d5c-a8e3-ae8040ec8501",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9105d115-14e6-4d93-9a1e-6eb674cfa64d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e38ac8c-fbbc-4c5b-aa47-34f7054c20f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"query_key_value\", \"dense\", \"dense_h_to_4h\", \"dense_4h_to_h\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e7504ba-743f-4d31-95b1-2ab3aa1594ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9bdf9ffcc3d4725846cd49fbd2c792a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49260a15b70b4e379849279f26d3b458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    cfg.model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True,\n",
    "    revision=\"2f5c3cd4eace6be6c0f12981f377fb35e5bf6ee5\",  # Using this version because running the new version gives error\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a6d6006-33b8-41f5-be15-9e259ef1236b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./SFT-Falcon-7b\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=2e-4,\n",
    "    logging_steps=20,\n",
    "    logging_strategy=\"steps\",\n",
    "    max_steps=100,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    fp16=True,\n",
    "    run_name=\"baseline-falcon-sft\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ee1e8e2-c0ab-4d53-b8a0-86a51a7eed0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c330de836eb047bd802e4f69d50fc781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import DataCollatorForCompletionOnlyLM, SFTTrainer\n",
    "\n",
    "supervised_finetuning_trainer = SFTTrainer(\n",
    "    base_model,\n",
    "    train_dataset=tokenized_dataset_train,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    peft_config=lora_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=2048,\n",
    "    data_collator=DataCollatorForCompletionOnlyLM(tokenizer=tokenizer, response_template=\"### Answer:\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c31d28c3-cf15-44f4-9171-31fe269c9e32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkami\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tmp/working/wandb/run-20230928_073041-34kl6l7b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kami/huggingface/runs/34kl6l7b' target=\"_blank\">baseline-falcon-sft</a></strong> to <a href='https://wandb.ai/kami/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kami/huggingface' target=\"_blank\">https://wandb.ai/kami/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kami/huggingface/runs/34kl6l7b' target=\"_blank\">https://wandb.ai/kami/huggingface/runs/34kl6l7b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 supervised_finetuning_trainer.train()                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1645</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1642 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>inner_training_loop = find_executable_batch_size(                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1643 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._inner_training_loop, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._train_batch_size, args.auto_find_batch_size  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1644 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1645 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> inner_training_loop(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1646 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>args=args,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1647 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>resume_from_checkpoint=resume_from_checkpoint,                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1648 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>trial=trial,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1916</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_training_loop</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1913 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>rng_to_sync = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1914 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1915 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>step = -<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1916 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> step, inputs <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">enumerate</span>(epoch_iterator):                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1917 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>total_batched_samples += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1918 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> rng_to_sync:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1919 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._load_rng_state(resume_from_checkpoint)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/utils/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataloader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">634</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__next__</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 631 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._sampler_iter <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 632 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># TODO(https://github.com/pytorch/pytorch/issues/76750)</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 633 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._reset()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore[call-arg]</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 634 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._next_data()                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 635 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._num_yielded += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 636 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._dataset_kind == _DatasetKind.Iterable <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> \\                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 637 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._IterableDataset_len_called <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> \\                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/utils/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataloader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">678</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_next_data</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 675 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 676 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_next_data</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 677 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>index = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._next_index()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># may raise StopIteration</span>                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 678 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._dataset_fetcher.fetch(index)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># may raise StopIteration</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 679 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._pin_memory:                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 680 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>data = _utils.pin_memory.pin_memory(data, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._pin_memory_device)            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 681 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> data                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">fetch.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">54</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fetch</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">51 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>data = [<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset[idx] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> idx <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> possibly_batched_index]                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">52 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">53 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset[possibly_batched_index]                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>54 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.collate_fn(data)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">55 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">data_collator.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">45</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  42 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> return_tensors == <span style=\"color: #808000; text-decoration-color: #808000\">\"tf\"</span>:                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  43 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.tf_call(features)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  44 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> return_tensors == <span style=\"color: #808000; text-decoration-color: #808000\">\"pt\"</span>:                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>  45 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.torch_call(features)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  46 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> return_tensors == <span style=\"color: #808000; text-decoration-color: #808000\">\"np\"</span>:                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  47 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.numpy_call(features)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  48 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/trl/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">104</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">torch_call</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">101 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>response_token_ids_start_idx = idx                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">102 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">103 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> response_token_ids_start_idx <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>104 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">105 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f'Could not find response key {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.response_token_ids<span style=\"color: #808000; text-decoration-color: #808000\">} in token</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">106 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>)                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">107 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>Could not find response key <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19468</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23688</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span><span style=\"font-weight: bold\">]</span> in token IDs <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2232</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26971</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">193</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">193</span>, \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33228</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19220</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">204</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5839</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1901</span>,\n",
       "          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">318</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2176</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">204</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9566</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19220</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">204</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17468</span>,\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">600</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11127</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">398</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">267</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2281</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26844</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">427</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15173</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">972</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">267</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5788</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2483</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3803</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">299</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">967</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,\n",
       "          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">299</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">724</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3378</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">271</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1623</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">248</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2483</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">271</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1151</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3644</span>,\n",
       "          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">271</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">248</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6868</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2507</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9566</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19220</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">204</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4552</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36916</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21621</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">94</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">273</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">830</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">986</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4698</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">413</span>,\n",
       "          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">650</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42655</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">273</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5200</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">272</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8475</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">275</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19220</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12732</span>,\n",
       "         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8628</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18910</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">532</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1148</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">272</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14922</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5837</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,\n",
       "         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9568</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11233</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14273</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13100</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15173</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12456</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16437</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15428</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22763</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3082</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8253</span>,\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2993</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19723</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14551</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5186</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">273</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3431</span>,\n",
       "         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8246</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">362</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5200</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">312</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19220</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30398</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5200</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">312</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19220</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1965</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19220</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15173</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1156</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">592</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3931</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14922</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">273</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1156</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">592</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3931</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12026</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">390</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2522</span>,\n",
       "         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2941</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13610</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5200</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">241</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49267</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">248</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46884</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9566</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19220</span>,\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">272</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">545</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8475</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4702</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">275</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1209</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5200</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">312</span>,\n",
       "         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9566</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19220</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">204</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12732</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8628</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19220</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18910</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">272</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">248</span>,\n",
       "         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2522</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2941</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">272</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14922</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5837</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9568</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11233</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14273</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13100</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15173</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12456</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16437</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15428</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22763</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3082</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8253</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2993</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19723</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14551</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5186</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">273</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3431</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8246</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>,\n",
       "          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">204</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64406</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3402</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14221</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">304</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5200</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">312</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1001</span>,\n",
       "         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2232</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">55564</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">193</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">193</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20309</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">248</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1863</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3381</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3078</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2101</span>,\n",
       "          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">431</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3582</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">248</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">758</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4901</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3253</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23688</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">808</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">314</span>,\n",
       "          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">532</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2369</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">204</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">70</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">341</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">319</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,\n",
       "          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">361</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">399</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1001</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2232</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16496</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">193</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">193</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1064</span>,\n",
       "          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">632</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1536</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">398</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19220</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3402</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">272</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13100</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5200</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">852</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>,\n",
       "          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">193</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">193</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9566</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19220</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">241</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5868</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18887</span>,\n",
       "          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">193</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">193</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">45</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9566</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19220</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">241</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17773</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27352</span>,\n",
       "          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">193</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">193</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9566</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19220</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">241</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5868</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">39948</span>,\n",
       "          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">193</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">193</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9566</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19220</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">267</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20382</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">493</span>,\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">62</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18192</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">427</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15173</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">193</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">193</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>,\n",
       "         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9566</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19220</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">241</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3734</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4179</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">275</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">248</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2522</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2941</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11331</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2232</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23688</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">361</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9566</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19220</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">267</span>,\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20382</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">493</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">62</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18192</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">427</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15173</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">193</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 supervised_finetuning_trainer.train()                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1645\u001b[0m in \u001b[92mtrain\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1642 \u001b[0m\u001b[2m│   │   \u001b[0minner_training_loop = find_executable_batch_size(                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1643 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._inner_training_loop, \u001b[96mself\u001b[0m._train_batch_size, args.auto_find_batch_size  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1644 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1645 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m inner_training_loop(                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1646 \u001b[0m\u001b[2m│   │   │   \u001b[0margs=args,                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1647 \u001b[0m\u001b[2m│   │   │   \u001b[0mresume_from_checkpoint=resume_from_checkpoint,                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1648 \u001b[0m\u001b[2m│   │   │   \u001b[0mtrial=trial,                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1916\u001b[0m in \u001b[92m_inner_training_loop\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1913 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mrng_to_sync = \u001b[94mTrue\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1914 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1915 \u001b[0m\u001b[2m│   │   │   \u001b[0mstep = -\u001b[94m1\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1916 \u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m step, inputs \u001b[95min\u001b[0m \u001b[96menumerate\u001b[0m(epoch_iterator):                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1917 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mtotal_batched_samples += \u001b[94m1\u001b[0m                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1918 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m rng_to_sync:                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1919 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._load_rng_state(resume_from_checkpoint)                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/utils/data/\u001b[0m\u001b[1;33mdataloader.py\u001b[0m:\u001b[94m634\u001b[0m in \u001b[92m__next__\u001b[0m           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 631 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._sampler_iter \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 632 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 633 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._reset()  \u001b[2m# type: ignore[call-arg]\u001b[0m                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 634 \u001b[2m│   │   │   \u001b[0mdata = \u001b[96mself\u001b[0m._next_data()                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 635 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._num_yielded += \u001b[94m1\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 636 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._dataset_kind == _DatasetKind.Iterable \u001b[95mand\u001b[0m \\                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 637 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._IterableDataset_len_called \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m \\                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/utils/data/\u001b[0m\u001b[1;33mdataloader.py\u001b[0m:\u001b[94m678\u001b[0m in \u001b[92m_next_data\u001b[0m         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 675 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 676 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_next_data\u001b[0m(\u001b[96mself\u001b[0m):                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 677 \u001b[0m\u001b[2m│   │   \u001b[0mindex = \u001b[96mself\u001b[0m._next_index()  \u001b[2m# may raise StopIteration\u001b[0m                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 678 \u001b[2m│   │   \u001b[0mdata = \u001b[96mself\u001b[0m._dataset_fetcher.fetch(index)  \u001b[2m# may raise StopIteration\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 679 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._pin_memory:                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 680 \u001b[0m\u001b[2m│   │   │   \u001b[0mdata = _utils.pin_memory.pin_memory(data, \u001b[96mself\u001b[0m._pin_memory_device)            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 681 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m data                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/\u001b[0m\u001b[1;33mfetch.py\u001b[0m:\u001b[94m54\u001b[0m in \u001b[92mfetch\u001b[0m             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m51 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mdata = [\u001b[96mself\u001b[0m.dataset[idx] \u001b[94mfor\u001b[0m idx \u001b[95min\u001b[0m possibly_batched_index]                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m52 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m53 \u001b[0m\u001b[2m│   │   │   \u001b[0mdata = \u001b[96mself\u001b[0m.dataset[possibly_batched_index]                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m54 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.collate_fn(data)                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m55 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/data/\u001b[0m\u001b[1;33mdata_collator.py\u001b[0m:\u001b[94m45\u001b[0m in \u001b[92m__call__\u001b[0m        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  42 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m return_tensors == \u001b[33m\"\u001b[0m\u001b[33mtf\u001b[0m\u001b[33m\"\u001b[0m:                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  43 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.tf_call(features)                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  44 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m return_tensors == \u001b[33m\"\u001b[0m\u001b[33mpt\u001b[0m\u001b[33m\"\u001b[0m:                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m  45 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.torch_call(features)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  46 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m return_tensors == \u001b[33m\"\u001b[0m\u001b[33mnp\u001b[0m\u001b[33m\"\u001b[0m:                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  47 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.numpy_call(features)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  48 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/trl/trainer/\u001b[0m\u001b[1;33mutils.py\u001b[0m:\u001b[94m104\u001b[0m in \u001b[92mtorch_call\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m101 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mresponse_token_ids_start_idx = idx                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m102 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m103 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m response_token_ids_start_idx \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m104 \u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m105 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m'\u001b[0m\u001b[33mCould not find response key \u001b[0m\u001b[33m{\u001b[0m\u001b[96mself\u001b[0m.response_token_ids\u001b[33m}\u001b[0m\u001b[33m in token\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m106 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m)                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m107 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0mCould not find response key \u001b[1m[\u001b[0m\u001b[1;36m19468\u001b[0m, \u001b[1;36m23688\u001b[0m, \u001b[1;36m37\u001b[0m\u001b[1m]\u001b[0m in token IDs \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m2232\u001b[0m, \u001b[1;36m26971\u001b[0m,   \u001b[1;36m193\u001b[0m,   \u001b[1;36m193\u001b[0m, \n",
       "\u001b[1;36m33228\u001b[0m, \u001b[1;36m19220\u001b[0m,   \u001b[1;36m204\u001b[0m,    \u001b[1;36m19\u001b[0m,  \u001b[1;36m5839\u001b[0m,  \u001b[1;36m1901\u001b[0m,\n",
       "          \u001b[1;36m318\u001b[0m,  \u001b[1;36m2176\u001b[0m,    \u001b[1;36m20\u001b[0m,   \u001b[1;36m204\u001b[0m,    \u001b[1;36m41\u001b[0m,  \u001b[1;36m9566\u001b[0m, \u001b[1;36m19220\u001b[0m,   \u001b[1;36m204\u001b[0m,    \u001b[1;36m19\u001b[0m, \u001b[1;36m17468\u001b[0m,\n",
       "           \u001b[1;36m34\u001b[0m,   \u001b[1;36m600\u001b[0m, \u001b[1;36m11127\u001b[0m,    \u001b[1;36m29\u001b[0m,    \u001b[1;36m20\u001b[0m,   \u001b[1;36m398\u001b[0m,   \u001b[1;36m267\u001b[0m,  \u001b[1;36m2281\u001b[0m, \u001b[1;36m26844\u001b[0m,   \u001b[1;36m427\u001b[0m,\n",
       "        \u001b[1;36m15173\u001b[0m,    \u001b[1;36m25\u001b[0m,   \u001b[1;36m972\u001b[0m,   \u001b[1;36m267\u001b[0m,  \u001b[1;36m5788\u001b[0m,  \u001b[1;36m2483\u001b[0m,  \u001b[1;36m3803\u001b[0m,   \u001b[1;36m299\u001b[0m,   \u001b[1;36m967\u001b[0m,    \u001b[1;36m23\u001b[0m,\n",
       "          \u001b[1;36m299\u001b[0m,   \u001b[1;36m724\u001b[0m,  \u001b[1;36m3378\u001b[0m,   \u001b[1;36m271\u001b[0m,  \u001b[1;36m1623\u001b[0m,   \u001b[1;36m248\u001b[0m,  \u001b[1;36m2483\u001b[0m,   \u001b[1;36m271\u001b[0m,  \u001b[1;36m1151\u001b[0m,  \u001b[1;36m3644\u001b[0m,\n",
       "          \u001b[1;36m271\u001b[0m,   \u001b[1;36m248\u001b[0m,  \u001b[1;36m6868\u001b[0m,  \u001b[1;36m2507\u001b[0m,    \u001b[1;36m25\u001b[0m,  \u001b[1;36m9566\u001b[0m, \u001b[1;36m19220\u001b[0m,   \u001b[1;36m204\u001b[0m,    \u001b[1;36m41\u001b[0m,  \u001b[1;36m4552\u001b[0m,\n",
       "        \u001b[1;36m36916\u001b[0m,    \u001b[1;36m23\u001b[0m, \u001b[1;36m21621\u001b[0m,    \u001b[1;36m94\u001b[0m,    \u001b[1;36m23\u001b[0m,   \u001b[1;36m273\u001b[0m,   \u001b[1;36m830\u001b[0m,   \u001b[1;36m986\u001b[0m,  \u001b[1;36m4698\u001b[0m,   \u001b[1;36m413\u001b[0m,\n",
       "          \u001b[1;36m650\u001b[0m, \u001b[1;36m42655\u001b[0m,   \u001b[1;36m273\u001b[0m,  \u001b[1;36m5200\u001b[0m,   \u001b[1;36m272\u001b[0m,  \u001b[1;36m8475\u001b[0m,   \u001b[1;36m275\u001b[0m, \u001b[1;36m19220\u001b[0m,    \u001b[1;36m25\u001b[0m, \u001b[1;36m12732\u001b[0m,\n",
       "         \u001b[1;36m8628\u001b[0m, \u001b[1;36m18910\u001b[0m,    \u001b[1;36m23\u001b[0m,   \u001b[1;36m532\u001b[0m,  \u001b[1;36m1148\u001b[0m,   \u001b[1;36m272\u001b[0m, \u001b[1;36m14922\u001b[0m,    \u001b[1;36m23\u001b[0m,  \u001b[1;36m5837\u001b[0m,    \u001b[1;36m23\u001b[0m,\n",
       "         \u001b[1;36m9568\u001b[0m,    \u001b[1;36m23\u001b[0m, \u001b[1;36m11233\u001b[0m,    \u001b[1;36m23\u001b[0m, \u001b[1;36m14273\u001b[0m,    \u001b[1;36m23\u001b[0m, \u001b[1;36m13100\u001b[0m,    \u001b[1;36m23\u001b[0m, \u001b[1;36m15173\u001b[0m,    \u001b[1;36m23\u001b[0m,\n",
       "        \u001b[1;36m12456\u001b[0m,    \u001b[1;36m23\u001b[0m, \u001b[1;36m16437\u001b[0m,    \u001b[1;36m23\u001b[0m, \u001b[1;36m15428\u001b[0m,    \u001b[1;36m23\u001b[0m, \u001b[1;36m22763\u001b[0m,    \u001b[1;36m23\u001b[0m,  \u001b[1;36m3082\u001b[0m,  \u001b[1;36m8253\u001b[0m,\n",
       "           \u001b[1;36m23\u001b[0m,  \u001b[1;36m2993\u001b[0m, \u001b[1;36m19723\u001b[0m,    \u001b[1;36m23\u001b[0m, \u001b[1;36m14551\u001b[0m,    \u001b[1;36m23\u001b[0m,  \u001b[1;36m5186\u001b[0m,    \u001b[1;36m23\u001b[0m,   \u001b[1;36m273\u001b[0m,  \u001b[1;36m3431\u001b[0m,\n",
       "         \u001b[1;36m8246\u001b[0m,    \u001b[1;36m23\u001b[0m,   \u001b[1;36m362\u001b[0m,  \u001b[1;36m5200\u001b[0m,   \u001b[1;36m312\u001b[0m, \u001b[1;36m19220\u001b[0m,    \u001b[1;36m25\u001b[0m, \u001b[1;36m30398\u001b[0m,  \u001b[1;36m5200\u001b[0m,   \u001b[1;36m312\u001b[0m,\n",
       "        \u001b[1;36m19220\u001b[0m,  \u001b[1;36m1965\u001b[0m, \u001b[1;36m19220\u001b[0m,    \u001b[1;36m23\u001b[0m, \u001b[1;36m15173\u001b[0m,    \u001b[1;36m23\u001b[0m,  \u001b[1;36m1156\u001b[0m,   \u001b[1;36m592\u001b[0m,  \u001b[1;36m3931\u001b[0m,    \u001b[1;36m23\u001b[0m,\n",
       "        \u001b[1;36m14922\u001b[0m,   \u001b[1;36m273\u001b[0m,  \u001b[1;36m1156\u001b[0m,   \u001b[1;36m592\u001b[0m,  \u001b[1;36m3931\u001b[0m,    \u001b[1;36m23\u001b[0m, \u001b[1;36m12026\u001b[0m,    \u001b[1;36m25\u001b[0m,   \u001b[1;36m390\u001b[0m,  \u001b[1;36m2522\u001b[0m,\n",
       "         \u001b[1;36m2941\u001b[0m, \u001b[1;36m13610\u001b[0m,  \u001b[1;36m5200\u001b[0m,   \u001b[1;36m241\u001b[0m, \u001b[1;36m49267\u001b[0m,    \u001b[1;36m23\u001b[0m,   \u001b[1;36m248\u001b[0m, \u001b[1;36m46884\u001b[0m,  \u001b[1;36m9566\u001b[0m, \u001b[1;36m19220\u001b[0m,\n",
       "           \u001b[1;36m23\u001b[0m,   \u001b[1;36m272\u001b[0m,   \u001b[1;36m545\u001b[0m,  \u001b[1;36m8475\u001b[0m,    \u001b[1;36m25\u001b[0m,  \u001b[1;36m4702\u001b[0m,   \u001b[1;36m275\u001b[0m,  \u001b[1;36m1209\u001b[0m,  \u001b[1;36m5200\u001b[0m,   \u001b[1;36m312\u001b[0m,\n",
       "         \u001b[1;36m9566\u001b[0m, \u001b[1;36m19220\u001b[0m,   \u001b[1;36m204\u001b[0m,    \u001b[1;36m41\u001b[0m, \u001b[1;36m12732\u001b[0m,  \u001b[1;36m8628\u001b[0m, \u001b[1;36m19220\u001b[0m, \u001b[1;36m18910\u001b[0m,   \u001b[1;36m272\u001b[0m,   \u001b[1;36m248\u001b[0m,\n",
       "         \u001b[1;36m2522\u001b[0m,  \u001b[1;36m2941\u001b[0m,    \u001b[1;36m23\u001b[0m,   \u001b[1;36m272\u001b[0m, \u001b[1;36m14922\u001b[0m,    \u001b[1;36m23\u001b[0m,  \u001b[1;36m5837\u001b[0m,    \u001b[1;36m23\u001b[0m,  \u001b[1;36m9568\u001b[0m,    \u001b[1;36m23\u001b[0m,\n",
       "        \u001b[1;36m11233\u001b[0m,    \u001b[1;36m23\u001b[0m, \u001b[1;36m14273\u001b[0m,    \u001b[1;36m23\u001b[0m, \u001b[1;36m13100\u001b[0m,    \u001b[1;36m23\u001b[0m, \u001b[1;36m15173\u001b[0m,    \u001b[1;36m23\u001b[0m, \u001b[1;36m12456\u001b[0m,    \u001b[1;36m23\u001b[0m,\n",
       "        \u001b[1;36m16437\u001b[0m,    \u001b[1;36m23\u001b[0m, \u001b[1;36m15428\u001b[0m,    \u001b[1;36m23\u001b[0m, \u001b[1;36m22763\u001b[0m,    \u001b[1;36m23\u001b[0m,  \u001b[1;36m3082\u001b[0m,  \u001b[1;36m8253\u001b[0m,    \u001b[1;36m23\u001b[0m,  \u001b[1;36m2993\u001b[0m,\n",
       "        \u001b[1;36m19723\u001b[0m,    \u001b[1;36m23\u001b[0m, \u001b[1;36m14551\u001b[0m,    \u001b[1;36m23\u001b[0m,  \u001b[1;36m5186\u001b[0m,    \u001b[1;36m23\u001b[0m,   \u001b[1;36m273\u001b[0m,  \u001b[1;36m3431\u001b[0m,  \u001b[1;36m8246\u001b[0m,    \u001b[1;36m25\u001b[0m,\n",
       "          \u001b[1;36m204\u001b[0m,    \u001b[1;36m19\u001b[0m, \u001b[1;36m64406\u001b[0m,  \u001b[1;36m3402\u001b[0m,    \u001b[1;36m23\u001b[0m, \u001b[1;36m14221\u001b[0m,   \u001b[1;36m304\u001b[0m,  \u001b[1;36m5200\u001b[0m,   \u001b[1;36m312\u001b[0m,  \u001b[1;36m1001\u001b[0m,\n",
       "         \u001b[1;36m2232\u001b[0m, \u001b[1;36m55564\u001b[0m,   \u001b[1;36m193\u001b[0m,   \u001b[1;36m193\u001b[0m, \u001b[1;36m20309\u001b[0m,   \u001b[1;36m248\u001b[0m,  \u001b[1;36m1863\u001b[0m,  \u001b[1;36m3381\u001b[0m,  \u001b[1;36m3078\u001b[0m,  \u001b[1;36m2101\u001b[0m,\n",
       "          \u001b[1;36m431\u001b[0m,  \u001b[1;36m3582\u001b[0m,   \u001b[1;36m248\u001b[0m,   \u001b[1;36m758\u001b[0m,  \u001b[1;36m4901\u001b[0m,  \u001b[1;36m3253\u001b[0m,    \u001b[1;36m25\u001b[0m, \u001b[1;36m23688\u001b[0m,   \u001b[1;36m808\u001b[0m,   \u001b[1;36m314\u001b[0m,\n",
       "          \u001b[1;36m532\u001b[0m,  \u001b[1;36m2369\u001b[0m,   \u001b[1;36m204\u001b[0m,    \u001b[1;36m70\u001b[0m,    \u001b[1;36m44\u001b[0m,    \u001b[1;36m23\u001b[0m,   \u001b[1;36m341\u001b[0m,    \u001b[1;36m23\u001b[0m,   \u001b[1;36m319\u001b[0m,    \u001b[1;36m23\u001b[0m,\n",
       "          \u001b[1;36m361\u001b[0m,    \u001b[1;36m23\u001b[0m,   \u001b[1;36m399\u001b[0m,    \u001b[1;36m72\u001b[0m,  \u001b[1;36m1001\u001b[0m,  \u001b[1;36m2232\u001b[0m, \u001b[1;36m16496\u001b[0m,   \u001b[1;36m193\u001b[0m,   \u001b[1;36m193\u001b[0m,  \u001b[1;36m1064\u001b[0m,\n",
       "          \u001b[1;36m632\u001b[0m,  \u001b[1;36m1536\u001b[0m,   \u001b[1;36m398\u001b[0m, \u001b[1;36m19220\u001b[0m,  \u001b[1;36m3402\u001b[0m,   \u001b[1;36m272\u001b[0m, \u001b[1;36m13100\u001b[0m,  \u001b[1;36m5200\u001b[0m,   \u001b[1;36m852\u001b[0m,    \u001b[1;36m42\u001b[0m,\n",
       "          \u001b[1;36m193\u001b[0m,   \u001b[1;36m193\u001b[0m,    \u001b[1;36m44\u001b[0m,    \u001b[1;36m20\u001b[0m,  \u001b[1;36m9566\u001b[0m, \u001b[1;36m19220\u001b[0m,    \u001b[1;36m23\u001b[0m,   \u001b[1;36m241\u001b[0m,  \u001b[1;36m5868\u001b[0m, \u001b[1;36m18887\u001b[0m,\n",
       "          \u001b[1;36m193\u001b[0m,   \u001b[1;36m193\u001b[0m,    \u001b[1;36m45\u001b[0m,    \u001b[1;36m20\u001b[0m,  \u001b[1;36m9566\u001b[0m, \u001b[1;36m19220\u001b[0m,    \u001b[1;36m23\u001b[0m,   \u001b[1;36m241\u001b[0m, \u001b[1;36m17773\u001b[0m, \u001b[1;36m27352\u001b[0m,\n",
       "          \u001b[1;36m193\u001b[0m,   \u001b[1;36m193\u001b[0m,    \u001b[1;36m46\u001b[0m,    \u001b[1;36m20\u001b[0m,  \u001b[1;36m9566\u001b[0m, \u001b[1;36m19220\u001b[0m,    \u001b[1;36m23\u001b[0m,   \u001b[1;36m241\u001b[0m,  \u001b[1;36m5868\u001b[0m, \u001b[1;36m39948\u001b[0m,\n",
       "          \u001b[1;36m193\u001b[0m,   \u001b[1;36m193\u001b[0m,    \u001b[1;36m47\u001b[0m,    \u001b[1;36m20\u001b[0m,  \u001b[1;36m9566\u001b[0m, \u001b[1;36m19220\u001b[0m,    \u001b[1;36m23\u001b[0m,   \u001b[1;36m267\u001b[0m, \u001b[1;36m20382\u001b[0m,   \u001b[1;36m493\u001b[0m,\n",
       "           \u001b[1;36m25\u001b[0m,    \u001b[1;36m62\u001b[0m,    \u001b[1;36m25\u001b[0m, \u001b[1;36m18192\u001b[0m,   \u001b[1;36m427\u001b[0m, \u001b[1;36m15173\u001b[0m,   \u001b[1;36m193\u001b[0m,   \u001b[1;36m193\u001b[0m,    \u001b[1;36m48\u001b[0m,    \u001b[1;36m20\u001b[0m,\n",
       "         \u001b[1;36m9566\u001b[0m, \u001b[1;36m19220\u001b[0m,    \u001b[1;36m23\u001b[0m,   \u001b[1;36m241\u001b[0m,  \u001b[1;36m3734\u001b[0m,  \u001b[1;36m4179\u001b[0m,   \u001b[1;36m275\u001b[0m,   \u001b[1;36m248\u001b[0m,  \u001b[1;36m2522\u001b[0m,  \u001b[1;36m2941\u001b[0m,\n",
       "        \u001b[1;36m11331\u001b[0m,  \u001b[1;36m2232\u001b[0m, \u001b[1;36m23688\u001b[0m,    \u001b[1;36m37\u001b[0m,   \u001b[1;36m361\u001b[0m,    \u001b[1;36m20\u001b[0m,  \u001b[1;36m9566\u001b[0m, \u001b[1;36m19220\u001b[0m,    \u001b[1;36m23\u001b[0m,   \u001b[1;36m267\u001b[0m,\n",
       "        \u001b[1;36m20382\u001b[0m,   \u001b[1;36m493\u001b[0m,    \u001b[1;36m25\u001b[0m,    \u001b[1;36m62\u001b[0m,    \u001b[1;36m25\u001b[0m, \u001b[1;36m18192\u001b[0m,   \u001b[1;36m427\u001b[0m, \u001b[1;36m15173\u001b[0m,   \u001b[1;36m193\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "supervised_finetuning_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe46915-549e-4e17-a5b5-f0c234e085fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
