{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79307949-c4b2-42e1-a931-15d9c0d61b13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModel, AutoModelForMultipleChoice, AutoTokenizer, Trainer, TrainingArguments\n",
    "from transformers.tokenization_utils_base import PaddingStrategy, PreTrainedTokenizerBase\n",
    "\n",
    "model_paths = [\"../output/001_additional_data/003/checkpoint-21000\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c566df2-5d44-4d9d-a591-55506cf05c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "option_to_index = {option: idx for idx, option in enumerate(\"ABCDE\")}\n",
    "index_to_option = {v: k for k, v in option_to_index.items()}\n",
    "\n",
    "\n",
    "def preprocess(example):\n",
    "    first_sentence = [example[\"prompt\"]] * 5\n",
    "    second_sentences = [example[option] for option in \"ABCDE\"]\n",
    "    tokenized_example = tokenizer(first_sentence, second_sentences, truncation=False)\n",
    "    tokenized_example[\"label\"] = option_to_index[example[\"answer\"]]\n",
    "\n",
    "    return tokenized_example\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "\n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3df846-ef92-4087-a767-68ce2b76ea8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "170f17d1-92a3-4740-b79b-f69e0efb34ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a3f612ed90040a7b841d1bc61a12294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.5 s, sys: 2.39 s, total: 6.89 s\n",
      "Wall time: 5.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "for model_path in model_paths:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "    test_df = pd.read_csv(\"../input/kaggle-llm-science-exam/test.csv\")\n",
    "    test_df[\n",
    "        \"answer\"\n",
    "    ] = \"A\"  # dummy answer that allows us to preprocess the test datataset using functionality that works for the train set\n",
    "\n",
    "    tokenized_test_dataset = Dataset.from_pandas(test_df.drop(columns=[\"id\"])).map(\n",
    "        preprocess, remove_columns=[\"prompt\", \"A\", \"B\", \"C\", \"D\", \"E\", \"answer\"]\n",
    "    )\n",
    "    data_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)\n",
    "    test_dataloader = DataLoader(tokenized_test_dataset, 10, shuffle=False, collate_fn=data_collator)\n",
    "\n",
    "    model = AutoModelForMultipleChoice.from_pretrained(model_path).cuda()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    labels = []\n",
    "    for batch in test_dataloader:\n",
    "        for k in batch.keys():\n",
    "            batch[k] = batch[k].cuda()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        labels.append(batch[\"labels\"].cpu().detach())\n",
    "        preds.append(outputs.logits.cpu().detach())\n",
    "\n",
    "    preds = torch.cat(preds)\n",
    "    labels = torch.cat(labels)\n",
    "    all_preds.append(preds)\n",
    "    all_labels.append(labels)\n",
    "\n",
    "all_preds = torch.stack(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df8fe578-a2d9-4393-8a9e-b86ffdf7df0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200, 5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9e6b4f2-a261-4cea-b4bc-8b9a8769dd45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 1, 2, 0, 4],\n",
       "        [3, 2, 1, 0, 4],\n",
       "        [2, 0, 4, 1, 3]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = all_preds.mean(0)\n",
    "predictions_as_ids = np.argsort(-test_predictions, 1)\n",
    "predictions_as_ids[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "037d7014-848c-4ae4-b722-3573f315648e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['D', 'B', 'C', 'A', 'E'],\n",
       "       ['D', 'C', 'B', 'A', 'E'],\n",
       "       ['C', 'A', 'E', 'B', 'D']], dtype='<U1')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_as_answer_letters = np.array(list(\"ABCDE\"))[predictions_as_ids]\n",
    "predictions_as_answer_letters[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83912bba-beab-4af2-be37-8e1cb58113c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D B C', 'D C B', 'C A E']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_as_string = test_df[\"prediction\"] = [\" \".join(row) for row in predictions_as_answer_letters[:, :3]]\n",
    "predictions_as_string[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76cd56de-eb83-47fc-9cae-ecedd5b03379",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>C A E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>C B A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>B A D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>D B C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>A E D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id prediction\n",
       "195  195      C A E\n",
       "196  196      C B A\n",
       "197  197      B A D\n",
       "198  198      D B C\n",
       "199  199      A E D"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = test_df[[\"id\", \"prediction\"]]\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "pd.read_csv(\"submission.csv\").tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d5d39d-a005-4a69-9500-ad510e6b60a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
