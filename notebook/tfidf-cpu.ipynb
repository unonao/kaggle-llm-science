{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b1bf166-9cf0-4fe2-b6ea-3c48d709cf88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import unicodedata\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10e39cfc-84d2-4ec2-8171-bd200645d9c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.7 s, sys: 2.03 s, total: 7.73 s\n",
      "Wall time: 17.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "paraphs_parsed_dataset = load_from_disk(\"../input/all-paraphs-parsed-expanded\")\n",
    "modified_texts = paraphs_parsed_dataset.map(\n",
    "    lambda example: {\n",
    "        \"temp_text\": f\"{example['title']} {example['section']} {example['text']}\".replace(\"\\n\", \" \").replace(\"'\", \"\")\n",
    "    },\n",
    "    num_proc=4,\n",
    ")[\"temp_text\"]\n",
    "\n",
    "wiki_df = pd.DataFrame({\"text\": modified_texts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fbae94e-f365-4c8a-853f-bc0f9b793a55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>answer</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>MOND is a theory that reduces the observed mis...</td>\n",
       "      <td>MOND is a theory that increases the discrepanc...</td>\n",
       "      <td>MOND is a theory that explains the missing bar...</td>\n",
       "      <td>MOND is a theory that reduces the discrepancy ...</td>\n",
       "      <td>MOND is a theory that eliminates the observed ...</td>\n",
       "      <td>D</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which of the following is an accurate definiti...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>A</td>\n",
       "      <td>Which of the following is an accurate definiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>The triskeles symbol was reconstructed as a fe...</td>\n",
       "      <td>The triskeles symbol is a representation of th...</td>\n",
       "      <td>The triskeles symbol is a representation of a ...</td>\n",
       "      <td>The triskeles symbol represents three interloc...</td>\n",
       "      <td>The triskeles symbol is a representation of th...</td>\n",
       "      <td>A</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the significance of regularization in ...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>C</td>\n",
       "      <td>What is the significance of regularization in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>D</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Which of the following statements accurately d...   \n",
       "1  Which of the following is an accurate definiti...   \n",
       "2  Which of the following statements accurately d...   \n",
       "3  What is the significance of regularization in ...   \n",
       "4  Which of the following statements accurately d...   \n",
       "\n",
       "                                                   A  \\\n",
       "0  MOND is a theory that reduces the observed mis...   \n",
       "1  Dynamic scaling refers to the evolution of sel...   \n",
       "2  The triskeles symbol was reconstructed as a fe...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   B  \\\n",
       "0  MOND is a theory that increases the discrepanc...   \n",
       "1  Dynamic scaling refers to the non-evolution of...   \n",
       "2  The triskeles symbol is a representation of th...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   C  \\\n",
       "0  MOND is a theory that explains the missing bar...   \n",
       "1  Dynamic scaling refers to the evolution of sel...   \n",
       "2  The triskeles symbol is a representation of a ...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   D  \\\n",
       "0  MOND is a theory that reduces the discrepancy ...   \n",
       "1  Dynamic scaling refers to the non-evolution of...   \n",
       "2  The triskeles symbol represents three interloc...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   E answer  \\\n",
       "0  MOND is a theory that eliminates the observed ...      D   \n",
       "1  Dynamic scaling refers to the evolution of sel...      A   \n",
       "2  The triskeles symbol is a representation of th...      A   \n",
       "3  Regularizing the mass-energy of an electron wi...      C   \n",
       "4  The angular spacing of features in the diffrac...      D   \n",
       "\n",
       "                                                text  \n",
       "0  Which of the following statements accurately d...  \n",
       "1  Which of the following is an accurate definiti...  \n",
       "2  Which of the following statements accurately d...  \n",
       "3  What is the significance of regularization in ...  \n",
       "4  Which of the following statements accurately d...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../preprocessed/901_concat/data2.csv\")\n",
    "\n",
    "df[\"text\"] = df.apply(\n",
    "    lambda row: f'{row[\"prompt\"]}\\n{row[\"prompt\"]}\\n{row[\"prompt\"]}\\n{row[\"A\"]}\\n{row[\"B\"]}\\n{row[\"C\"]}\\n{row[\"D\"]}\\n{row[\"E\"]}',\n",
    "    axis=1,\n",
    ").values\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a70db504-0e01-40ae-a652-f804b7a1338f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_words = [\n",
    "    \"each\",\n",
    "    \"you\",\n",
    "    \"the\",\n",
    "    \"use\",\n",
    "    \"used\",\n",
    "    \"where\",\n",
    "    \"themselves\",\n",
    "    \"nor\",\n",
    "    \"it's\",\n",
    "    \"how\",\n",
    "    \"don't\",\n",
    "    \"just\",\n",
    "    \"your\",\n",
    "    \"about\",\n",
    "    \"himself\",\n",
    "    \"with\",\n",
    "    \"weren't\",\n",
    "    \"hers\",\n",
    "    \"wouldn't\",\n",
    "    \"more\",\n",
    "    \"its\",\n",
    "    \"were\",\n",
    "    \"his\",\n",
    "    \"their\",\n",
    "    \"then\",\n",
    "    \"been\",\n",
    "    \"myself\",\n",
    "    \"re\",\n",
    "    \"not\",\n",
    "    \"ours\",\n",
    "    \"will\",\n",
    "    \"needn\",\n",
    "    \"which\",\n",
    "    \"here\",\n",
    "    \"hadn\",\n",
    "    \"it\",\n",
    "    \"our\",\n",
    "    \"there\",\n",
    "    \"than\",\n",
    "    \"most\",\n",
    "    \"couldn't\",\n",
    "    \"both\",\n",
    "    \"some\",\n",
    "    \"for\",\n",
    "    \"up\",\n",
    "    \"couldn\",\n",
    "    \"that'll\",\n",
    "    \"she's\",\n",
    "    \"over\",\n",
    "    \"this\",\n",
    "    \"now\",\n",
    "    \"until\",\n",
    "    \"these\",\n",
    "    \"few\",\n",
    "    \"haven\",\n",
    "    \"of\",\n",
    "    \"wouldn\",\n",
    "    \"into\",\n",
    "    \"too\",\n",
    "    \"to\",\n",
    "    \"very\",\n",
    "    \"shan\",\n",
    "    \"before\",\n",
    "    \"the\",\n",
    "    \"they\",\n",
    "    \"between\",\n",
    "    \"doesn't\",\n",
    "    \"are\",\n",
    "    \"was\",\n",
    "    \"out\",\n",
    "    \"we\",\n",
    "    \"me\",\n",
    "    \"after\",\n",
    "    \"has\",\n",
    "    \"isn't\",\n",
    "    \"have\",\n",
    "    \"such\",\n",
    "    \"should\",\n",
    "    \"yourselves\",\n",
    "    \"or\",\n",
    "    \"during\",\n",
    "    \"herself\",\n",
    "    \"doing\",\n",
    "    \"in\",\n",
    "    \"shouldn't\",\n",
    "    \"won't\",\n",
    "    \"when\",\n",
    "    \"do\",\n",
    "    \"through\",\n",
    "    \"she\",\n",
    "    \"having\",\n",
    "    \"him\",\n",
    "    \"haven't\",\n",
    "    \"against\",\n",
    "    \"itself\",\n",
    "    \"that\",\n",
    "    \"did\",\n",
    "    \"theirs\",\n",
    "    \"can\",\n",
    "    \"those\",\n",
    "    \"own\",\n",
    "    \"so\",\n",
    "    \"and\",\n",
    "    \"who\",\n",
    "    \"you've\",\n",
    "    \"yourself\",\n",
    "    \"her\",\n",
    "    \"he\",\n",
    "    \"only\",\n",
    "    \"what\",\n",
    "    \"ourselves\",\n",
    "    \"again\",\n",
    "    \"had\",\n",
    "    \"you'd\",\n",
    "    \"is\",\n",
    "    \"other\",\n",
    "    \"why\",\n",
    "    \"while\",\n",
    "    \"from\",\n",
    "    \"them\",\n",
    "    \"if\",\n",
    "    \"above\",\n",
    "    \"does\",\n",
    "    \"whom\",\n",
    "    \"yours\",\n",
    "    \"but\",\n",
    "    \"being\",\n",
    "    \"wasn't\",\n",
    "    \"be\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "932a71a9-71b8-4618-9c96-c230e4855c65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'\", 'd', 'doesn', 'don', 'isn', 'll', 's', 'shouldn', 't', 've', 'wasn', 'weren', 'won'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of vectorizer vocab is 50256\n",
      "length of vectorizer vocab is 50256\n",
      "CPU times: user 7min 3s, sys: 1.44 s, total: 7min 4s\n",
      "Wall time: 7min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus_df_valid = df[\"text\"]\n",
    "modified_texts = wiki_df[\"text\"]\n",
    "\n",
    "vectorizer1 = TfidfVectorizer(\n",
    "    ngram_range=(1, 2), token_pattern=r\"(?u)\\b[\\w/.-]+\\b|!|/|\\?|\\\"|\\'\", stop_words=stop_words\n",
    ")\n",
    "vectorizer1.fit(corpus_df_valid)\n",
    "vocab_df_valid = vectorizer1.get_feature_names_out()\n",
    "print(f\"length of vectorizer vocab is {len(vocab_df_valid)}\")\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),\n",
    "    token_pattern=r\"(?u)\\b[\\w/.-]+\\b|!|/|\\?|\\\"|\\'\",\n",
    "    stop_words=stop_words,\n",
    "    vocabulary=vocab_df_valid,\n",
    ")\n",
    "vectorizer.fit(modified_texts)\n",
    "corpus_tf_idf = vectorizer.transform(corpus_df_valid)\n",
    "print(f\"length of vectorizer vocab is {len(vectorizer.get_feature_names_out())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95d53a6b-d900-4d3d-8398-600810469f2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 50256)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tf_idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7b06bfd-8f64-4a4c-bcd6-087ff66f9328",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f52e71d0e31446297ed6ea4b62a6280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 28s, sys: 11.2 s, total: 8min 40s\n",
      "Wall time: 8min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "chunk_size = 100000\n",
    "top_per_chunk = 10\n",
    "top_per_query = 10\n",
    "\n",
    "all_chunk_top_indices = []\n",
    "all_chunk_top_values = []\n",
    "\n",
    "for idx in tqdm(range(0, len(wiki_df), chunk_size)):\n",
    "    wiki_vectors = vectorizer.transform(wiki_df[\"text\"][idx : idx + chunk_size])\n",
    "    temp_scores = (corpus_tf_idf * wiki_vectors.T).toarray()\n",
    "    chunk_top_indices = temp_scores.argpartition(-top_per_chunk, axis=1)[:, -top_per_chunk:]\n",
    "    chunk_top_values = temp_scores[np.arange(temp_scores.shape[0])[:, np.newaxis], chunk_top_indices]\n",
    "\n",
    "    all_chunk_top_indices.append(chunk_top_indices + idx)\n",
    "    all_chunk_top_values.append(chunk_top_values)\n",
    "\n",
    "top_indices_array = np.concatenate(all_chunk_top_indices, axis=1)\n",
    "top_values_array = np.concatenate(all_chunk_top_values, axis=1)\n",
    "\n",
    "merged_top_scores = np.sort(top_values_array, axis=1)[:, -top_per_query:]\n",
    "merged_top_indices = top_values_array.argsort(axis=1)[:, -top_per_query:]\n",
    "articles_indices = top_indices_array[np.arange(top_indices_array.shape[0])[:, np.newaxis], merged_top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29e9058a-4d73-4a77-902f-627cc108ae2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4360fa58-af8a-4487-853b-85d8f001e52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "364ee62f-d5f4-43d1-b982-e305d2580544",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Born reciprocity Born reciprocity However Borns idea of a quantum metric operator was later taken up by Hideki Yukawa when developing his nonlocal quantum theory in the 1950s. In 1981, Eduardo R. Caianiello proposed a \"maximal acceleration\", similarly as there is a minimal length at Planck scale, and this concept of maximal acceleration has been expanded upon by others. It has also been suggested that Born reciprocity may be the underlying physical reason for the T-duality symmetry in string theory, and that Born reciprocity may be of relevance to developing a quantum geometry.Born chose the term \"reciprocity\" for the reason that in a crystal lattice, the motion of a particle can be described in p-space by means of the reciprocal lattice.\n",
      "\n",
      "Glossary of Lie groups and Lie algebras M maximal 1. For \"maximal compact subgroup\", see #compact. 2. For \"maximal torus\", see #torus.\n",
      "\n",
      "That that is is that that is not is not is that it it is That that is is that that is not is not is that it it is That that is is that that is. \"Not\" is not. Is that it? It is. That that is is that that is not. Is \"not is that\" it? It is. That that is is that that is not \"is not\". Is that it? It is.\n",
      "\n",
      "PHP syntax and semantics Basic language constructs Delimiters The PHP processor only parses code within its delimiters. Anything outside its delimiters is sent directly to the output and not parsed by PHP. The only open/close delimiters allowed by PSR-1 are \"<?php\" and \"?>\" or <?= and ?>.\n",
      "\n",
      "\n",
      "Who proposed the concept of \"maximal acceleration\"?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Eduardo R. Caianiello'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 96\n",
    "print(wiki_df.iloc[int(articles_indices[index, -1])].text)\n",
    "print()\n",
    "print(wiki_df.iloc[int(articles_indices[index, -2])].text)\n",
    "print()\n",
    "print(wiki_df.iloc[int(articles_indices[index, -3])].text)\n",
    "print()\n",
    "print(wiki_df.iloc[int(articles_indices[index, -4])].text)\n",
    "print()\n",
    "\n",
    "print()\n",
    "print(df.iloc[index].prompt)\n",
    "df.iloc[index][df.iloc[index].answer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e5bc5f-07f5-4630-9270-4390d96d4623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
