{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07be3ebd-dda5-4a32-bb66-e2ba8f0125bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/working\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/working'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd ..\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7265eae-4a8c-415d-8a71-9c63ea0f9afd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retrieval\n",
    "class Config:\n",
    "    sim_model = \"BAAI/bge-small-en\"\n",
    "    sim_max_length = 384\n",
    "\n",
    "    batch_size = 32\n",
    "    num_sentences_include = 20\n",
    "    doc_top_k = 3\n",
    "    window_size = 5\n",
    "    sliding_size = 4\n",
    "\n",
    "    # index\n",
    "    wiki_index_path = \"preprocessed/320_doc_index/001/all.parquet\"\n",
    "    index_path = \"preprocessed/320_doc_index/001/ivfpq_index.faiss\"\n",
    "\n",
    "    # wiki b\n",
    "    wiki_dir = \"input/llm-science-wikipedia-data-b\"\n",
    "\n",
    "\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01e9e88d-d741-4d2b-80e1-f755603bad3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import ctypes\n",
    "import gc\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from collections.abc import Iterable\n",
    "\n",
    "import blingfire as bf\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from faiss import read_index, write_index\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "libc = ctypes.CDLL(\"libc.so.6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79e82669-cc91-4254-a4c9-8e8fa84701a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_chunk_by_sliding_window(text_list: list[str], window_size: int, sliding_size: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    text のリストをsliding windowで結合する。window_size個のtextが含まれるまで結合し、sliding_size個ずつずらして結合する。\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    for i in range(0, len(text_list), sliding_size):\n",
    "        chunk = \" \".join(text_list[i : i + window_size])\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def extract_sections(text: str) -> list[tuple[str, str]]:\n",
    "    pattern = re.compile(r\"#{2,}\\s?(.*?)\\s?#{2,}\")\n",
    "    sections = []\n",
    "\n",
    "    matches = list(pattern.finditer(text))\n",
    "    start_idx = 0\n",
    "\n",
    "    if len(matches) == 0:\n",
    "        sections.append((\"\", text))\n",
    "        return sections\n",
    "\n",
    "    for i, match in enumerate(matches):\n",
    "        if i == 0:\n",
    "            end_idx = match.start()\n",
    "            sections.append((\"\", text[start_idx:end_idx].strip()))\n",
    "\n",
    "        start_idx = match.end()\n",
    "        end_idx = matches[i + 1].start() if i + 1 < len(matches) else len(text)\n",
    "        section = (match.group(1).strip(), text[start_idx:end_idx].strip())\n",
    "        if section[0] not in [\"See also\", \"References\", \"Further reading\", \"External links\"]:\n",
    "            sections.append(section)\n",
    "\n",
    "        start_idx = end_idx\n",
    "\n",
    "    # 空のtextの場合は飛ばす\n",
    "    sections = [section for section in sections if len(section[1].split(\" \")) >= 3]\n",
    "    return sections\n",
    "\n",
    "\n",
    "def sentencize(\n",
    "    titles: Iterable[str],\n",
    "    documents: Iterable[str],\n",
    "    document_ids: Iterable,\n",
    "    window_size: int = 3,\n",
    "    sliding_size: int = 2,\n",
    "    filter_len: int = 5,\n",
    "    filter_len_max: int = 500,\n",
    "    disable_progress_bar: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Split a document into sentences. Can be used with `sectionize_documents`\n",
    "    to further split documents into more manageable pieces. Takes in offsets\n",
    "    to ensure that after splitting, the sentences can be matched to the\n",
    "    location in the original documents.\n",
    "\n",
    "    :param documents: Iterable containing documents which are strings\n",
    "    :param document_ids: Iterable containing document unique identifiers\n",
    "    :param filter_len: Minimum character length of a sentence (otherwise filter out)\n",
    "    :return: Pandas DataFrame containing the columns `document_id`, `text`, `section`, `offset`\n",
    "    \"\"\"\n",
    "\n",
    "    document_sentences = []\n",
    "    for title, document, document_id in tqdm(\n",
    "        zip(titles, documents, document_ids), total=len(documents), disable=disable_progress_bar\n",
    "    ):\n",
    "        try:\n",
    "            # chunk にまとめる\n",
    "            ## 念のため改行をスペースに変換\n",
    "            document = document.replace(\"\\n\", \" \")\n",
    "            _, sentence_offsets = bf.text_to_sentences_and_offsets(document)\n",
    "            section_sentences = []\n",
    "            for o in sentence_offsets:\n",
    "                if filter_len < o[1] - o[0] and o[1] - o[0] < filter_len_max:\n",
    "                    section_sentences.append(document[o[0] : o[1]])\n",
    "            chunks = extract_chunk_by_sliding_window(section_sentences, window_size, sliding_size)\n",
    "\n",
    "            for chunk in chunks:\n",
    "                row = {}\n",
    "                row[\"document_id\"] = document_id\n",
    "                row[\"text\"] = f\"{title} > {chunk}\"\n",
    "                row[\"offset\"] = (0, 0)\n",
    "                document_sentences.append(row)\n",
    "        except:\n",
    "            continue\n",
    "    return pd.DataFrame(document_sentences)\n",
    "\n",
    "\n",
    "def sectionize_documents(\n",
    "    titles: Iterable[str],\n",
    "    documents: Iterable[str],\n",
    "    document_ids: Iterable,\n",
    "    disable_progress_bar: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Obtains the sections of the imaging reports and returns only the\n",
    "    selected sections (defaults to FINDINGS, IMPRESSION, and ADDENDUM).\n",
    "\n",
    "    :param documents: Iterable containing documents which are strings\n",
    "    :param document_ids: Iterable containing document unique identifiers\n",
    "    :param disable_progress_bar: Flag to disable tqdm progress bar\n",
    "    :return: Pandas DataFrame containing the columns `document_id`, `text`, `offset`\n",
    "    \"\"\"\n",
    "    processed_documents = []\n",
    "    for title, document_id, document in tqdm(\n",
    "        zip(titles, document_ids, documents), total=len(documents), disable=disable_progress_bar\n",
    "    ):\n",
    "        row = {}\n",
    "        text, start, end = (document, 0, len(document))\n",
    "        row[\"document_id\"] = document_id\n",
    "        row[\"text\"] = text\n",
    "        row[\"offset\"] = (start, end)\n",
    "\n",
    "        processed_documents.append(row)\n",
    "\n",
    "    _df = pd.DataFrame(processed_documents)\n",
    "    if _df.shape[0] > 0:\n",
    "        return _df.sort_values([\"document_id\", \"offset\"]).reset_index(drop=True)\n",
    "    else:\n",
    "        return _df\n",
    "\n",
    "\n",
    "def relevant_title_retrieval(\n",
    "    df: pd.DataFrame,\n",
    "    index_path: str,\n",
    "    model: SentenceTransformer,\n",
    "    top_k: int = 3,\n",
    "    batch_size: int = 32,\n",
    ") -> pd.DataFrame:\n",
    "    sentence_index = read_index(index_path)  # index 読み込み\n",
    "    res = faiss.StandardGpuResources()  # use a single GPU\n",
    "    co = faiss.GpuClonerOptions()\n",
    "    co.useFloat16 = True\n",
    "    sentence_index = faiss.index_cpu_to_gpu(res, 0, sentence_index, co)\n",
    "    sentence_index.nprobe = 10\n",
    "    prompt_embeddings = model.encode(\n",
    "        df.prompt_answer_stem.values,\n",
    "        batch_size=batch_size,\n",
    "        device=\"cuda\",\n",
    "        show_progress_bar=True,\n",
    "        # convert_to_tensor=True,\n",
    "        normalize_embeddings=True,\n",
    "    )\n",
    "    prompt_embeddings = prompt_embeddings.astype(np.float32)\n",
    "    # prompt_embeddings = prompt_embeddings.detach().cpu().numpy()\n",
    "    search_score, search_index = sentence_index.search(prompt_embeddings, top_k)\n",
    "    res.noTempMemory()\n",
    "    del res\n",
    "    del sentence_index\n",
    "    del prompt_embeddings\n",
    "    _ = gc.collect()\n",
    "    libc.malloc_trim(0)\n",
    "    return search_score, search_index\n",
    "\n",
    "\n",
    "def get_wikipedia_file_data(\n",
    "    search_score: np.ndarray,\n",
    "    search_index: np.ndarray,\n",
    "    wiki_index_path: str,\n",
    ") -> pd.DataFrame:\n",
    "    wiki_index_df = pd.read_parquet(wiki_index_path, columns=[\"id\", \"file\"])\n",
    "    wikipedia_file_data = []\n",
    "    for i, (scr, idx) in tqdm(enumerate(zip(search_score, search_index)), total=len(search_score)):\n",
    "        _df = wiki_index_df.loc[idx].copy()\n",
    "        _df[\"prompt_id\"] = i\n",
    "        wikipedia_file_data.append(_df)\n",
    "    wikipedia_file_data = pd.concat(wikipedia_file_data).reset_index(drop=True)\n",
    "    wikipedia_file_data = (\n",
    "        wikipedia_file_data[[\"id\", \"prompt_id\", \"file\"]]\n",
    "        .drop_duplicates()\n",
    "        .sort_values([\"file\", \"id\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    ## Save memory - delete df since it is no longer necessary\n",
    "    del wiki_index_df\n",
    "    _ = gc.collect()\n",
    "    libc.malloc_trim(0)\n",
    "    return wikipedia_file_data\n",
    "\n",
    "\n",
    "def get_full_text_data(\n",
    "    wikipedia_file_data: pd.DataFrame,\n",
    "    wiki_dir: str,\n",
    "):\n",
    "    ## Get the full text data\n",
    "    wiki_text_data = []\n",
    "    for file in tqdm(wikipedia_file_data.file.unique(), total=len(wikipedia_file_data.file.unique())):\n",
    "        _id = [str(i) for i in wikipedia_file_data[wikipedia_file_data[\"file\"] == file][\"id\"].tolist()]\n",
    "        _df = pd.read_parquet(f\"{wiki_dir}/{file}\", columns=[\"id\", \"title\", \"text\"])\n",
    "        _df_temp = _df[_df[\"id\"].isin(_id)].copy()\n",
    "        del _df\n",
    "        _ = gc.collect()\n",
    "        libc.malloc_trim(0)\n",
    "        wiki_text_data.append(_df_temp)\n",
    "    wiki_text_data = pd.concat(wiki_text_data).drop_duplicates().reset_index(drop=True)\n",
    "    _ = gc.collect()\n",
    "    libc.malloc_trim(0)\n",
    "    return wiki_text_data\n",
    "\n",
    "\n",
    "def extract_contexts_from_matching_pairs(\n",
    "    df: pd.DataFrame,\n",
    "    processed_wiki_text_data: pd.DataFrame,\n",
    "    wikipedia_file_data: pd.DataFrame,\n",
    "    wiki_data_embeddings: np.ndarray,\n",
    "    question_embeddings: np.ndarray,\n",
    "    num_sentences_include: int = 5,\n",
    "):\n",
    "    results = {\"contexts\": [], \"sim_min\": [], \"sim_max\": [], \"sim_mean\": [], \"sim_std\": [], \"sim_num\": []}\n",
    "    for r in tqdm(df.itertuples(), total=len(df)):\n",
    "        prompt_id = r.Index\n",
    "        prompt_indices = processed_wiki_text_data[\n",
    "            processed_wiki_text_data[\"document_id\"].isin(\n",
    "                wikipedia_file_data[wikipedia_file_data[\"prompt_id\"] == prompt_id][\"id\"].values\n",
    "            )\n",
    "        ].index.values\n",
    "        assert prompt_indices.shape[0] > 0\n",
    "        prompt_index = faiss.index_factory(wiki_data_embeddings.shape[1], \"Flat\")\n",
    "        prompt_index.add(wiki_data_embeddings[prompt_indices])\n",
    "        ## Get the top matches\n",
    "        ss, ii = prompt_index.search(question_embeddings[np.newaxis, prompt_id], num_sentences_include)\n",
    "        context = \"\"\n",
    "        total_len = 0\n",
    "        num = 0\n",
    "        for _s, _i in zip(ss[0], ii[0]):\n",
    "            if total_len > 1000 or _s >= 1.0:\n",
    "                break\n",
    "            text = processed_wiki_text_data.loc[prompt_indices][\"text\"].iloc[_i]\n",
    "            context += text + \" \"\n",
    "            total_len += len(text.split(\" \"))\n",
    "            num += 1\n",
    "        results[\"contexts\"].append(context)\n",
    "        results[\"sim_max\"].append(ss[0][:num].max())\n",
    "        results[\"sim_min\"].append(ss[0][:num].min())\n",
    "        results[\"sim_mean\"].append(ss[0][:num].mean())\n",
    "        results[\"sim_std\"].append(ss[0][:num].std())\n",
    "        results[\"sim_num\"].append(num)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beb14724-e935-457c-b1da-11483682de82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_190/3580508950.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df = pd.read_csv(\"input/kaggle-llm-science-exam/test.csv\").drop(\"id\", 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              prompt  \\\n",
      "0  Which of the following statements accurately d...   \n",
      "1  Which of the following is an accurate definiti...   \n",
      "2  Which of the following statements accurately d...   \n",
      "3  What is the significance of regularization in ...   \n",
      "4  Which of the following statements accurately d...   \n",
      "\n",
      "                                                   A  \\\n",
      "0  MOND is a theory that reduces the observed mis...   \n",
      "1  Dynamic scaling refers to the evolution of sel...   \n",
      "2  The triskeles symbol was reconstructed as a fe...   \n",
      "3  Regularizing the mass-energy of an electron wi...   \n",
      "4  The angular spacing of features in the diffrac...   \n",
      "\n",
      "                                                   B  \\\n",
      "0  MOND is a theory that increases the discrepanc...   \n",
      "1  Dynamic scaling refers to the non-evolution of...   \n",
      "2  The triskeles symbol is a representation of th...   \n",
      "3  Regularizing the mass-energy of an electron wi...   \n",
      "4  The angular spacing of features in the diffrac...   \n",
      "\n",
      "                                                   C  \\\n",
      "0  MOND is a theory that explains the missing bar...   \n",
      "1  Dynamic scaling refers to the evolution of sel...   \n",
      "2  The triskeles symbol is a representation of a ...   \n",
      "3  Regularizing the mass-energy of an electron wi...   \n",
      "4  The angular spacing of features in the diffrac...   \n",
      "\n",
      "                                                   D  \\\n",
      "0  MOND is a theory that reduces the discrepancy ...   \n",
      "1  Dynamic scaling refers to the non-evolution of...   \n",
      "2  The triskeles symbol represents three interloc...   \n",
      "3  Regularizing the mass-energy of an electron wi...   \n",
      "4  The angular spacing of features in the diffrac...   \n",
      "\n",
      "                                                   E  \\\n",
      "0  MOND is a theory that eliminates the observed ...   \n",
      "1  Dynamic scaling refers to the evolution of sel...   \n",
      "2  The triskeles symbol is a representation of th...   \n",
      "3  Regularizing the mass-energy of an electron wi...   \n",
      "4  The angular spacing of features in the diffrac...   \n",
      "\n",
      "                                          answer_all  \\\n",
      "0  MOND is a theory that reduces the observed mis...   \n",
      "1  Dynamic scaling refers to the evolution of sel...   \n",
      "2  The triskeles symbol was reconstructed as a fe...   \n",
      "3  Regularizing the mass-energy of an electron wi...   \n",
      "4  The angular spacing of features in the diffrac...   \n",
      "\n",
      "                                  prompt_answer_stem  \n",
      "0  Which of the following statements accurately d...  \n",
      "1  Which of the following is an accurate definiti...  \n",
      "2  Which of the following statements accurately d...  \n",
      "3  What is the significance of regularization in ...  \n",
      "4  Which of the following statements accurately d...  \n",
      "【title 検索】\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3795043dbbf4e439e832794bec4eee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer(cfg.sim_model, device=\"cuda\")\n",
    "model.max_seq_length = cfg.sim_max_length\n",
    "model = model.half()\n",
    "\n",
    "df = pd.read_csv(\"input/kaggle-llm-science-exam/test.csv\").drop(\"id\", 1)\n",
    "df[[\"A\", \"B\", \"C\", \"D\", \"E\"]] = df[[\"A\", \"B\", \"C\", \"D\", \"E\"]].fillna(\"\")\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df[\"answer_all\"] = df.apply(lambda x: \" \".join([x[\"A\"], x[\"B\"], x[\"C\"], x[\"D\"], x[\"E\"]]), axis=1)\n",
    "df[\"prompt_answer_stem\"] = df[\"prompt\"] + \" \" + df[\"answer_all\"]\n",
    "df[\"prompt_answer_stem\"] = df[\"prompt_answer_stem\"].str.replace('\"', \"\")\n",
    "df[\"prompt_answer_stem\"] = df[\"prompt_answer_stem\"].str.replace(\"“\", \"\")\n",
    "df[\"prompt_answer_stem\"] = df[\"prompt_answer_stem\"].str.replace(\"”\", \"\")\n",
    "\n",
    "\n",
    "# title 検索\n",
    "print(\"【title 検索】\")\n",
    "search_score, search_index = relevant_title_retrieval(\n",
    "    df,\n",
    "    cfg.index_path,\n",
    "    model,\n",
    "    top_k=cfg.doc_top_k,\n",
    "    batch_size=cfg.batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26d7edb2-9571-4b5e-a70a-d65ec61e3da8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10068762, 0.12946892, 0.12976813],\n",
       "       [0.1351223 , 0.15178347, 0.18356371],\n",
       "       [0.12990236, 0.13123703, 0.14057088],\n",
       "       [0.15044713, 0.16522694, 0.17006326],\n",
       "       [0.1450553 , 0.14929318, 0.161304  ],\n",
       "       [0.11162901, 0.12615228, 0.14367723],\n",
       "       [0.18997455, 0.19947195, 0.20539188],\n",
       "       [0.18377972, 0.18975115, 0.1910677 ],\n",
       "       [0.17236137, 0.18586063, 0.19104397],\n",
       "       [0.14987922, 0.16003966, 0.1659534 ],\n",
       "       [0.12615454, 0.15469241, 0.15862799],\n",
       "       [0.12249088, 0.1330868 , 0.15158391],\n",
       "       [0.09007239, 0.13666892, 0.14142656],\n",
       "       [0.12980413, 0.155334  , 0.16912293],\n",
       "       [0.13855219, 0.17639446, 0.18048668],\n",
       "       [0.1260724 , 0.21255589, 0.21269822],\n",
       "       [0.1490879 , 0.16588974, 0.19193196],\n",
       "       [0.15161109, 0.15481806, 0.20971203],\n",
       "       [0.1295793 , 0.15160513, 0.15559006],\n",
       "       [0.09423387, 0.15567255, 0.16606808],\n",
       "       [0.10964394, 0.18514276, 0.20093536],\n",
       "       [0.10188675, 0.15523934, 0.1681087 ],\n",
       "       [0.19200468, 0.195786  , 0.20589304],\n",
       "       [0.12109542, 0.15620184, 0.16213155],\n",
       "       [0.18887329, 0.19897914, 0.20857573],\n",
       "       [0.17681372, 0.21690941, 0.22406483],\n",
       "       [0.1368444 , 0.13727093, 0.14814186],\n",
       "       [0.08746505, 0.0938673 , 0.15951061],\n",
       "       [0.07943887, 0.12258124, 0.14865065],\n",
       "       [0.12957883, 0.18172812, 0.19680977],\n",
       "       [0.14773154, 0.17210293, 0.17601204],\n",
       "       [0.18188071, 0.1827147 , 0.18472242],\n",
       "       [0.07965565, 0.13286686, 0.13549376],\n",
       "       [0.16408253, 0.16413951, 0.16414118],\n",
       "       [0.09365845, 0.14829409, 0.15973973],\n",
       "       [0.15416813, 0.1639812 , 0.17333043],\n",
       "       [0.13451195, 0.1496625 , 0.164145  ],\n",
       "       [0.17585278, 0.2004776 , 0.20302606],\n",
       "       [0.13615775, 0.16873789, 0.16896105],\n",
       "       [0.17259836, 0.17373633, 0.1818819 ],\n",
       "       [0.13422418, 0.14653802, 0.14955711],\n",
       "       [0.17171359, 0.19138217, 0.19899058],\n",
       "       [0.16428876, 0.18555331, 0.19222999],\n",
       "       [0.12471843, 0.14668179, 0.15353417],\n",
       "       [0.11502206, 0.11556458, 0.14041448],\n",
       "       [0.10883689, 0.13873649, 0.14247394],\n",
       "       [0.16354656, 0.1772542 , 0.17966032],\n",
       "       [0.19913149, 0.20061755, 0.2007029 ],\n",
       "       [0.11967444, 0.1310432 , 0.14019918],\n",
       "       [0.13793206, 0.15195179, 0.15517735],\n",
       "       [0.13353372, 0.17472279, 0.19475889],\n",
       "       [0.1397047 , 0.16300583, 0.16492724],\n",
       "       [0.15805864, 0.15978289, 0.16579247],\n",
       "       [0.1948812 , 0.21119809, 0.213588  ],\n",
       "       [0.20402527, 0.20614457, 0.20670366],\n",
       "       [0.14010465, 0.15552521, 0.15818167],\n",
       "       [0.15842795, 0.16562426, 0.17979908],\n",
       "       [0.16562271, 0.17528391, 0.17806911],\n",
       "       [0.15121686, 0.16460156, 0.16800547],\n",
       "       [0.12644625, 0.13340402, 0.1675353 ],\n",
       "       [0.20052314, 0.20475912, 0.20651722],\n",
       "       [0.18141961, 0.18145752, 0.1874733 ],\n",
       "       [0.17078114, 0.18970466, 0.1908102 ],\n",
       "       [0.14484572, 0.20474291, 0.20647478],\n",
       "       [0.16467202, 0.17171574, 0.17176843],\n",
       "       [0.13500261, 0.13805139, 0.16266203],\n",
       "       [0.1350472 , 0.18249989, 0.20592546],\n",
       "       [0.15962029, 0.1893735 , 0.20297956],\n",
       "       [0.14114761, 0.14982033, 0.17247725],\n",
       "       [0.22245502, 0.23552132, 0.23594236],\n",
       "       [0.23695493, 0.23959732, 0.24229145],\n",
       "       [0.13751864, 0.14970064, 0.15418029],\n",
       "       [0.1413207 , 0.14942837, 0.15291524],\n",
       "       [0.15467262, 0.15916085, 0.16972637],\n",
       "       [0.17438078, 0.21478224, 0.22168112],\n",
       "       [0.16345263, 0.17553473, 0.18213034],\n",
       "       [0.15770483, 0.17498732, 0.17799616],\n",
       "       [0.1899271 , 0.19030595, 0.19652987],\n",
       "       [0.1771009 , 0.22453737, 0.23882389],\n",
       "       [0.13179946, 0.14680886, 0.15092611],\n",
       "       [0.17253172, 0.17272985, 0.17434406],\n",
       "       [0.134413  , 0.15069914, 0.15168464],\n",
       "       [0.13008285, 0.16797829, 0.17043209],\n",
       "       [0.12655902, 0.13817883, 0.15214443],\n",
       "       [0.1154747 , 0.13933682, 0.16165257],\n",
       "       [0.17245102, 0.17914104, 0.18634701],\n",
       "       [0.17306209, 0.17726755, 0.18309283],\n",
       "       [0.18301964, 0.22441196, 0.23934603],\n",
       "       [0.15256047, 0.17393243, 0.17951202],\n",
       "       [0.15605712, 0.16337311, 0.1714747 ],\n",
       "       [0.08856869, 0.14282942, 0.17152882],\n",
       "       [0.13175154, 0.15526819, 0.17311525],\n",
       "       [0.1108911 , 0.16635633, 0.17336845],\n",
       "       [0.14124131, 0.18338275, 0.18601418],\n",
       "       [0.17875242, 0.17877054, 0.18069911],\n",
       "       [0.12897074, 0.18503952, 0.19717407],\n",
       "       [0.20425868, 0.21202183, 0.21747112],\n",
       "       [0.14116383, 0.15547705, 0.19233966],\n",
       "       [0.13758183, 0.17518228, 0.17702591],\n",
       "       [0.14097404, 0.17276764, 0.17647815],\n",
       "       [0.19281936, 0.19597912, 0.19840491],\n",
       "       [0.16993213, 0.2172594 , 0.22057402],\n",
       "       [0.15241528, 0.2033596 , 0.20409203],\n",
       "       [0.1959815 , 0.19845676, 0.20218062],\n",
       "       [0.10254401, 0.1559844 , 0.15656257],\n",
       "       [0.08197796, 0.12421918, 0.16224813],\n",
       "       [0.18133736, 0.18814611, 0.18900657],\n",
       "       [0.18958282, 0.2153902 , 0.22542095],\n",
       "       [0.12494051, 0.17893744, 0.18734264],\n",
       "       [0.17736244, 0.19376516, 0.19781303],\n",
       "       [0.12410903, 0.14204001, 0.16448665],\n",
       "       [0.09810734, 0.17978811, 0.1812048 ],\n",
       "       [0.18591976, 0.20657825, 0.2079215 ],\n",
       "       [0.16251898, 0.20230365, 0.21061969],\n",
       "       [0.10707283, 0.19631529, 0.19698524],\n",
       "       [0.18199825, 0.19072366, 0.21387076],\n",
       "       [0.08394277, 0.14730144, 0.14895523],\n",
       "       [0.14529324, 0.15932083, 0.18021297],\n",
       "       [0.1469183 , 0.19022512, 0.19393015],\n",
       "       [0.12404478, 0.15818739, 0.161304  ],\n",
       "       [0.13486958, 0.14431572, 0.16968846],\n",
       "       [0.2011528 , 0.20167303, 0.20927238],\n",
       "       [0.13799894, 0.15041208, 0.16091108],\n",
       "       [0.1842835 , 0.21619463, 0.22249222],\n",
       "       [0.18303943, 0.18698096, 0.18809962],\n",
       "       [0.18587112, 0.22554457, 0.22609127],\n",
       "       [0.16436434, 0.17794418, 0.18133712],\n",
       "       [0.10649467, 0.16604078, 0.16839945],\n",
       "       [0.14994025, 0.21010876, 0.21225023],\n",
       "       [0.13973379, 0.16979259, 0.18281436],\n",
       "       [0.17983055, 0.19399571, 0.2108059 ],\n",
       "       [0.11142313, 0.14056373, 0.14648128],\n",
       "       [0.19286966, 0.19596434, 0.20688534],\n",
       "       [0.08209908, 0.1677947 , 0.18069434],\n",
       "       [0.16296005, 0.17895341, 0.18282652],\n",
       "       [0.1517539 , 0.15851927, 0.158705  ],\n",
       "       [0.13362682, 0.16918802, 0.1707077 ],\n",
       "       [0.21196604, 0.23042679, 0.23731017],\n",
       "       [0.18451285, 0.19043684, 0.20485497],\n",
       "       [0.18018198, 0.20332432, 0.20474863],\n",
       "       [0.16854477, 0.20621419, 0.2075243 ],\n",
       "       [0.17390823, 0.17515707, 0.1837697 ],\n",
       "       [0.1286676 , 0.1682446 , 0.17207575],\n",
       "       [0.16386557, 0.17518997, 0.18432546],\n",
       "       [0.13207555, 0.18314004, 0.18416095],\n",
       "       [0.1984334 , 0.20766401, 0.20849943],\n",
       "       [0.12102914, 0.13933372, 0.1568873 ],\n",
       "       [0.1374749 , 0.14558876, 0.14874864],\n",
       "       [0.14785671, 0.1800108 , 0.18112183],\n",
       "       [0.1287806 , 0.15875983, 0.16074347],\n",
       "       [0.11907721, 0.17472935, 0.18459892],\n",
       "       [0.108953  , 0.14722109, 0.1490817 ],\n",
       "       [0.18210268, 0.1843934 , 0.19217205],\n",
       "       [0.08360654, 0.1533184 , 0.1818366 ],\n",
       "       [0.22153974, 0.22324848, 0.23360753],\n",
       "       [0.14433026, 0.17557693, 0.1838522 ],\n",
       "       [0.12232494, 0.15490937, 0.17256594],\n",
       "       [0.14679193, 0.1556027 , 0.17845404],\n",
       "       [0.1235081 , 0.20914412, 0.21035385],\n",
       "       [0.10289359, 0.14281273, 0.16346407],\n",
       "       [0.12804389, 0.16257429, 0.1752572 ],\n",
       "       [0.12135625, 0.17882872, 0.18694746],\n",
       "       [0.11010528, 0.13227224, 0.149652  ],\n",
       "       [0.12490129, 0.13525295, 0.1713469 ],\n",
       "       [0.11431694, 0.12726355, 0.14710283],\n",
       "       [0.14551401, 0.17362332, 0.17962313],\n",
       "       [0.09918678, 0.15784621, 0.18726301],\n",
       "       [0.16896391, 0.1750381 , 0.18515301],\n",
       "       [0.09446383, 0.16119623, 0.16597939],\n",
       "       [0.12729621, 0.1470561 , 0.15080261],\n",
       "       [0.11003661, 0.1355663 , 0.16597366],\n",
       "       [0.16640139, 0.17412531, 0.1806494 ],\n",
       "       [0.19425106, 0.2050476 , 0.20551562],\n",
       "       [0.13892496, 0.15673351, 0.15833426],\n",
       "       [0.19132996, 0.19184494, 0.19415522],\n",
       "       [0.13855326, 0.16072083, 0.17010188],\n",
       "       [0.15260983, 0.18589401, 0.18828201],\n",
       "       [0.13955832, 0.14598036, 0.15127373],\n",
       "       [0.20217657, 0.20442438, 0.2105546 ],\n",
       "       [0.17467856, 0.17581272, 0.18046081],\n",
       "       [0.1461525 , 0.19692302, 0.20192862],\n",
       "       [0.15078855, 0.16638327, 0.1818664 ],\n",
       "       [0.18775368, 0.18808055, 0.18821287],\n",
       "       [0.13575292, 0.14414573, 0.18823576],\n",
       "       [0.14836454, 0.17146015, 0.1767832 ],\n",
       "       [0.13461256, 0.16650105, 0.17202544],\n",
       "       [0.13962221, 0.16398096, 0.16501713],\n",
       "       [0.11999607, 0.16162884, 0.16321862],\n",
       "       [0.18287706, 0.18634987, 0.19031096],\n",
       "       [0.15331078, 0.16871953, 0.19123077],\n",
       "       [0.12718749, 0.14332032, 0.14637303],\n",
       "       [0.1361363 , 0.1568495 , 0.1741476 ],\n",
       "       [0.1203835 , 0.14775968, 0.18774319],\n",
       "       [0.13134432, 0.14670897, 0.17617846],\n",
       "       [0.10930133, 0.12181306, 0.13962817],\n",
       "       [0.10645413, 0.1076082 , 0.12780881],\n",
       "       [0.21824145, 0.21958804, 0.22059417],\n",
       "       [0.15948129, 0.16660285, 0.17273271],\n",
       "       [0.13195181, 0.1450274 , 0.1459167 ],\n",
       "       [0.1648438 , 0.19527435, 0.20925045]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb642a5-0893-4175-987a-67e57980a0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
