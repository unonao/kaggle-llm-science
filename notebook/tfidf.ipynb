{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b1bf166-9cf0-4fe2-b6ea-3c48d709cf88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import unicodedata\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00dc863b-214c-48b7-8c56-9d42a09c1cae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import cudf\n",
    "import cuml\n",
    "import cupy\n",
    "from cuml import PCA\n",
    "from cuml.feature_extraction.text import TfidfVectorizer\n",
    "from cuml.neighbors import NearestNeighbors\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))  # 使用言語に応じて変更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10e39cfc-84d2-4ec2-8171-bd200645d9c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.9 s, sys: 1.4 s, total: 6.3 s\n",
      "Wall time: 6.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "paraphs_parsed_dataset = load_from_disk(\"../input/all-paraphs-parsed-expanded\")\n",
    "modified_texts = paraphs_parsed_dataset.map(\n",
    "    lambda example: {\n",
    "        \"temp_text\": f\"{example['title']} {example['section']} {example['text']}\".replace(\"\\n\", \" \").replace(\"'\", \"\")\n",
    "    },\n",
    "    num_proc=4,\n",
    ")[\"temp_text\"]\n",
    "\n",
    "wiki_df = pd.DataFrame({\"text\": modified_texts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b445140f-3dae-428f-9318-264ce941c18f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fbae94e-f365-4c8a-853f-bc0f9b793a55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e449f2aa84e44822874e52ff3d31cc5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=525320), Label(value='0 / 525320')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "\n",
    "\n",
    "def clean_text_for_fts(text):\n",
    "    token_pattern = re.compile(r\"(?u)\\b[\\w/.-]+\\b|!|/|\\?|\\\"|\\'\")\n",
    "    text = \" \".join(token_pattern.findall(text))\n",
    "    return text\n",
    "\n",
    "\n",
    "wiki_df[\"tokenized_text\"] = wiki_df[\"text\"].parallel_apply(clean_text_for_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0fcdfec3-74e7-4e81-9c80-4a7380cfae0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which of the following statements accurately d 2.5 2-5'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text_for_fts(text):\n",
    "    token_pattern = re.compile(r\"(?u)\\b[\\w/.-]+\\b|!|/|\\?|\\\"|\\'\")\n",
    "    text = \" \".join(token_pattern.findall(text))\n",
    "    return text\n",
    "\n",
    "\n",
    "clean_text_for_fts(\"Which of the following statements accurately d... 2.5 2-5\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c74d9d16-a729-4f4f-860f-34d06590431f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de26db733214855876d1650c7193e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=300), Label(value='0 / 300'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>answer</th>\n",
       "      <th>all_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>MOND is a theory that reduces the observed mis...</td>\n",
       "      <td>MOND is a theory that increases the discrepanc...</td>\n",
       "      <td>MOND is a theory that explains the missing bar...</td>\n",
       "      <td>MOND is a theory that reduces the discrepancy ...</td>\n",
       "      <td>MOND is a theory that eliminates the observed ...</td>\n",
       "      <td>D</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which of the following is an accurate definiti...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>A</td>\n",
       "      <td>Which of the following is an accurate definiti...</td>\n",
       "      <td>Which of the following is an accurate definiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>The triskeles symbol was reconstructed as a fe...</td>\n",
       "      <td>The triskeles symbol is a representation of th...</td>\n",
       "      <td>The triskeles symbol is a representation of a ...</td>\n",
       "      <td>The triskeles symbol represents three interloc...</td>\n",
       "      <td>The triskeles symbol is a representation of th...</td>\n",
       "      <td>A</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the significance of regularization in ...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>C</td>\n",
       "      <td>What is the significance of regularization in ...</td>\n",
       "      <td>What is the significance of regularization in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>D</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Which of the following statements accurately d...   \n",
       "1  Which of the following is an accurate definiti...   \n",
       "2  Which of the following statements accurately d...   \n",
       "3  What is the significance of regularization in ...   \n",
       "4  Which of the following statements accurately d...   \n",
       "\n",
       "                                                   A  \\\n",
       "0  MOND is a theory that reduces the observed mis...   \n",
       "1  Dynamic scaling refers to the evolution of sel...   \n",
       "2  The triskeles symbol was reconstructed as a fe...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   B  \\\n",
       "0  MOND is a theory that increases the discrepanc...   \n",
       "1  Dynamic scaling refers to the non-evolution of...   \n",
       "2  The triskeles symbol is a representation of th...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   C  \\\n",
       "0  MOND is a theory that explains the missing bar...   \n",
       "1  Dynamic scaling refers to the evolution of sel...   \n",
       "2  The triskeles symbol is a representation of a ...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   D  \\\n",
       "0  MOND is a theory that reduces the discrepancy ...   \n",
       "1  Dynamic scaling refers to the non-evolution of...   \n",
       "2  The triskeles symbol represents three interloc...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   E answer  \\\n",
       "0  MOND is a theory that eliminates the observed ...      D   \n",
       "1  Dynamic scaling refers to the evolution of sel...      A   \n",
       "2  The triskeles symbol is a representation of th...      A   \n",
       "3  Regularizing the mass-energy of an electron wi...      C   \n",
       "4  The angular spacing of features in the diffrac...      D   \n",
       "\n",
       "                                            all_text  \\\n",
       "0  Which of the following statements accurately d...   \n",
       "1  Which of the following is an accurate definiti...   \n",
       "2  Which of the following statements accurately d...   \n",
       "3  What is the significance of regularization in ...   \n",
       "4  Which of the following statements accurately d...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  Which of the following statements accurately d...  \n",
       "1  Which of the following is an accurate definiti...  \n",
       "2  Which of the following statements accurately d...  \n",
       "3  What is the significance of regularization in ...  \n",
       "4  Which of the following statements accurately d...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../preprocessed/901_concat/data2.csv\")\n",
    "\n",
    "df[\"all_text\"] = df.apply(\n",
    "    lambda row: f'{row[\"prompt\"]}\\n{row[\"A\"]}\\n{row[\"B\"]}\\n{row[\"C\"]}\\n{row[\"D\"]}\\n{row[\"E\"]}',\n",
    "    axis=1,\n",
    ").values\n",
    "df[\"tokenized_text\"] = df[\"all_text\"].parallel_apply(clean_text_for_fts)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "932a71a9-71b8-4618-9c96-c230e4855c65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10295\n",
      "CPU times: user 130 ms, sys: 20.8 ms, total: 151 ms\n",
      "Wall time: 148 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as SkTfidfVectorizer\n",
    "\n",
    "corpus_df_valid = df[\"tokenized_text\"]\n",
    "\n",
    "vectorizer1 = SkTfidfVectorizer(ngram_range=(1, 1), stop_words=list(stop_words))\n",
    "vectorizer1.fit(corpus_df_valid)\n",
    "vocab_df_valid = vectorizer1.get_feature_names_out()\n",
    "print(len(vocab_df_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb261ad2-6b68-4a27-8890-dc2e73a5a34a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.98 s, sys: 4.91 s, total: 6.89 s\n",
      "Wall time: 7.16 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<cuml.feature_extraction._tfidf_vectorizer.TfidfVectorizer at 0x7f064e876350>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 1), stop_words=list(stop_words), vocabulary=cudf.Series(vocab_df_valid))\n",
    "vectorizer.fit(wiki_df[\"tokenized_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15e7ecc9-6bb9-4b31-b0b6-11d33df67b71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 179 ms, sys: 94 µs, total: 179 ms\n",
      "Wall time: 176 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9439"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as SkTfidfVectorizer\n",
    "\n",
    "corpus_df_valid = df[\"all_text\"]\n",
    "\n",
    "vectorizer1 = SkTfidfVectorizer(ngram_range=(1, 2), stop_words=stop_words)\n",
    "vectorizer1.fit(df[\"all_text\"])\n",
    "vocab_df_valid = vectorizer1.get_feature_names_out()\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words=stop_words, vocabulary=vocab_df_valid)\n",
    "vectorizer.fit(wiki_df[\"text\"])\n",
    "\n",
    "%%time\n",
    "vectorizer = SkTfidfVectorizer(\n",
    "    ngram_range=(1, 2),\n",
    "    token_pattern=r\"(?u)\\b[\\w/.-]+\\b|!|/|\\?|\\\"|\\'\",\n",
    "    stop_words=list(stop_words),\n",
    "    vocabulary=vocab_df_valid,\n",
    ")\n",
    "vectorizer.fit(wiki_df[\"text\"])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7b06bfd-8f64-4a4c-bcd6-087ff66f9328",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_size = 100000\n",
    "top_per_chunk = 10\n",
    "top_per_query = 10\n",
    "\n",
    "all_chunk_top_indices = []\n",
    "all_chunk_top_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95d53a6b-d900-4d3d-8398-600810469f2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 367)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tf_idf = vectorizer.transform(corpus_df_valid)\n",
    "corpus_tf_idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8149a704-e271-444b-a157-ff9b81e5b579",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 167 ms, sys: 322 ms, total: 489 ms\n",
      "Wall time: 486 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wiki_vectors = vectorizer.transform(wiki_df[\"text\"][0 : 0 + chunk_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0869a720-6924-4c8d-8c8b-3df8374570f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.9 ms, sys: 8.6 ms, total: 29.5 ms\n",
      "Wall time: 27 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "temp_scores = (corpus_tf_idf * wiki_vectors.T).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ab9ac46-3e15-49e7-aac0-9edb4388ea55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb144d235164284b9f49c7411a02a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.92 s, sys: 8.34 s, total: 12.3 s\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "chunk_size = 100000\n",
    "top_per_chunk = 10\n",
    "top_per_query = 10\n",
    "\n",
    "all_chunk_top_indices = []\n",
    "all_chunk_top_values = []\n",
    "\n",
    "for idx in tqdm(range(0, len(wiki_df), chunk_size)):\n",
    "    wiki_vectors = vectorizer.transform(wiki_df[\"text\"][idx : idx + chunk_size])\n",
    "    temp_scores = (corpus_tf_idf * wiki_vectors.T).toarray()\n",
    "    chunk_top_indices = temp_scores.argpartition(-top_per_chunk, axis=1)[:, -top_per_chunk:]\n",
    "    chunk_top_values = temp_scores[np.arange(temp_scores.shape[0])[:, np.newaxis], chunk_top_indices]\n",
    "\n",
    "    all_chunk_top_indices.append(chunk_top_indices + idx)\n",
    "    all_chunk_top_values.append(chunk_top_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "388e97c4-a9f0-4f27-a9cc-1e8282bb080b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_indices_array = np.concatenate(all_chunk_top_indices, axis=1)\n",
    "top_values_array = np.concatenate(all_chunk_top_values, axis=1)\n",
    "\n",
    "merged_top_scores = np.sort(top_values_array, axis=1)[:, -top_per_query:]\n",
    "merged_top_indices = top_values_array.argsort(axis=1)[:, -top_per_query:]\n",
    "articles_indices = top_indices_array[np.arange(top_indices_array.shape[0])[:, np.newaxis], merged_top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "364ee62f-d5f4-43d1-b982-e305d2580544",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antiferromagnetism Antiferromagnetic materials Antiferromagnets can couple to ferromagnets, for instance, through a mechanism known as exchange bias, in which the ferromagnetic film is either grown upon the antiferromagnet or annealed in an aligning magnetic field, causing the surface atoms of the ferromagnet to align with the surface atoms of the antiferromagnet. This provides the ability to \"pin\" the orientation of a ferromagnetic film, which provides one of the main uses in so-called spin valves, which are the basis of magnetic sensors including modern hard disk drive read heads. The temperature at or above which an antiferromagnetic layer loses its ability to \"pin\" the magnetization direction of an adjacent ferromagnetic layer is called the blocking temperature of that layer and is usually lower than the Néel temperature.\n",
      "\n",
      "Bismuth ferrite Bismuth ferrite Bismuth ferrite (BiFeO3, also commonly referred to as BFO in materials science) is an inorganic chemical compound with perovskite structure and one of the most promising multiferroic materials. The room-temperature phase of BiFeO3 is classed as rhombohedral belonging to the space group R3c. It is synthesized in bulk and thin film form and both its antiferromagnetic (G type ordering) Néel temperature (approximately 653 K) and ferroelectric Curie temperature are well above room temperature (approximately 1100K). Ferroelectric polarization occurs along the pseudocubic direction ( 111 ⟩c ) with a magnitude of 90–95 μC/cm2.\n",
      "\n",
      "Shrink wrap Manufacture The family of shrink films has broadened over the years with many multi-layer constructions being sold today. Shrink film attributes include shrink, sealability, optics, toughness, and slip. With regard to shrink properties, there are onset temperature, free shrink, shrink force, shrink temperature range, memory, and overall package appearance.\n",
      "\n",
      "\n",
      "Which of the following statements accurately describes the blocking temperature of an antiferromagnetic layer in a spin valve?\n",
      "The blocking temperature of an antiferromagnetic layer in a spin valve is the temperature at which the magnetization of the ferromagnetic layer becomes aligned with the magnetic field. The blocking temperature is typically higher than the Néel temperature.\n",
      "The blocking temperature of an antiferromagnetic layer in a spin valve is the temperature below which the layer loses its ability to \"pin\" the magnetization direction of an adjacent ferromagnetic layer. The blocking temperature is typically higher than the Néel temperature.\n",
      "The blocking temperature of an antiferromagnetic layer in a spin valve is the temperature at which the ferromagnetic layer becomes completely demagnetized. The blocking temperature is typically higher than the Néel temperature.\n",
      "The blocking temperature of an antiferromagnetic layer in a spin valve is the temperature at or above which the layer ceases to prevent the orientation of an adjacent ferromagnetic layer. The blocking temperature is typically lower than the Néel temperature.\n",
      "The blocking temperature of an antiferromagnetic layer in a spin valve is the temperature at which the ferromagnetic layer loses its ability to \"pin\" the magnetization direction of an adjacent antiferromagnetic layer. The blocking temperature is typically higher than the Néel temperature.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "prompt            Which of the following statements accurately d...\n",
       "A                 The blocking temperature of an antiferromagnet...\n",
       "B                 The blocking temperature of an antiferromagnet...\n",
       "C                 The blocking temperature of an antiferromagnet...\n",
       "D                 The blocking temperature of an antiferromagnet...\n",
       "E                 The blocking temperature of an antiferromagnet...\n",
       "answer                                                            D\n",
       "all_text          Which of the following statements accurately d...\n",
       "tokenized_text    Which of the following statements accurately d...\n",
       "Name: 7, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 7\n",
    "print(wiki_df.iloc[int(articles_indices[index, -1])].text)\n",
    "print()\n",
    "print(wiki_df.iloc[int(articles_indices[index, -2])].text)\n",
    "print()\n",
    "print(wiki_df.iloc[int(articles_indices[index, -3])].text)\n",
    "print()\n",
    "\n",
    "print()\n",
    "print(df.iloc[index].all_text)\n",
    "df.iloc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e5bc5f-07f5-4630-9270-4390d96d4623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
